{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U transformers datasets sentencepiece peft accelerate evaluate\n",
    "# --OR--\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import login, Repository\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    TaskType,\n",
    "    PeftModel, \n",
    "    PeftConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"Salesforce/codet5-large\" # actual model\n",
    "\n",
    "new_model = \"CODEX-codet5-large\" # name of the new fine-tuned model\n",
    "\n",
    "tokenizer_path = \"tokenizer\"\n",
    "\n",
    "dataset_path = \"dataset\"  # dataset dir path\n",
    "\n",
    "# dataset = \"CodexAI/Deepseek-Coder\"  # dataset name at huggingface\n",
    "\n",
    "# repo_url = f'https://huggingface.co/datasets/{dataset}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login('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',add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Dataset\n",
    "Clone the dataset from HF, it's fast as fuck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- repo = Repository(local_dir=dataset_path,clone_from=repo_url)\n",
    "repo.git_pull() -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_data(dir_name):\n",
    "\n",
    "  data=[]\n",
    "  for root_folder in os.listdir(dir_name):\n",
    "    if root_folder!=\".git\" and root_folder!=\".gitattributes\":\n",
    "      for files in os.listdir(os.path.join(dir_name,root_folder)):\n",
    "        if files.endswith(\".json\"):\n",
    "          with open(os.path.join(dir_name,root_folder,files),\"r\")as f:\n",
    "            json_file=json.load(f)\n",
    "            data.append(json_file)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading dataset from ./{dataset_path}/\")\n",
    "json_data=load_json_data(dataset_path)\n",
    "print(f\"Length of loaded dataset is: {len(json_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=json_data  # in case if this is required again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Limit = 1000\n",
    "Dataset limit is set to 1000 and this bcz of testing this script. For actual training change this value\n",
    "`json_data[:1000]` to something greater or simply comment the cell below to use the complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data=json_data[:1000]\n",
    "print(f\"Length of dataset is: {len(json_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "df=Dataset.from_list(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting dataset instance\n",
    "Here dataset instance are printed just to see the dataset, skip these steps bcz you like to skip steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['instruction'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['output'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split\n",
    "If you want to evaluate the model on other dataset then load that dataset and skip these steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Spliting dataset...\")\n",
    "df=df.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df['train']\n",
    "test=df['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = tokenizer(train['instruction'][0])\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(instruction.input_ids)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_string(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Vocab size : {tokenizer.vocab_size}\")\n",
    "print(f\"max length : {tokenizer.model_max_length}\")\n",
    "print(f\"model input : {tokenizer.model_input_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(train['instruction'][0],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(data):\n",
    "  input_col=tokenizer(data['instruction'],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n",
    "  target_col=tokenizer(data['output'],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n",
    "\n",
    "  return {\n",
    "      \"input_ids\":input_col[\"input_ids\"],\n",
    "      \"attention_mask\":input_col[\"attention_mask\"],\n",
    "      \"labels\":target_col[\"input_ids\"]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tokenizing dataset...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mapping train data...\")\n",
    "train=train.map(tokenize_data,batched=True)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mappig test data...\")\n",
    "test=test.map(tokenize_data,batched=True)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.remove_columns([\"instruction\",\"output\"])\n",
    "test=test.remove_columns([\"instruction\",\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f'trainable model parameters: {trainable_model_params}\\n \\\n",
    "            all model parameters: {all_model_params} \\n \\\n",
    "            percentage of trainable model parameters: {(trainable_model_params / all_model_params) * 100} %'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n",
    "    device={\"\":0}\n",
    "    torch_type=torch.bfloat16\n",
    "else:\n",
    "    device=\"cpu\"\n",
    "    torch_type=torch.bfloat16\n",
    "    print(\"I am begging for mercy already!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(base_model,device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA Config for PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32,  # rank 16,32,64\n",
    "    lora_alpha=16, # LoRA Scaling factor keep 16 or 32\n",
    "    target_modules=['q', 'v'], # The modules(for example, attention blocks) to apply the LoRA update matrices.\n",
    "    lora_dropout = 0.1, # 0.05\n",
    "    bias='none',\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM ## flan-t5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(model, lora_config)\n",
    "print(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"BF16 support is {transformers.utils.import_utils.is_torch_bf16_gpu_available()}\")   # must check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    run_name =\"./loggings\",\n",
    "    overwrite_output_dir=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    learning_rate=5e-5, # default, change to (1e-3) later\n",
    "    gradient_accumulation_steps=1,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "    auto_find_batch_size = True, # for CUDA out of memory \n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    bf16=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    save_strategy=\"no\",\n",
    "    log_level=\"info\",\n",
    "    logging_first_step=True,\n",
    "    report_to='none' ## can be wandb, but we dont need right now!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer, \n",
    "    model=model,\n",
    "    # model=peft_model \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Seq2SeqTrainer(\n",
    "    model=model, # using the base model for now\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting trainer...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"finished. Saving model...\")\n",
    "model.save_pretrained(new_model)\n",
    "tokenizer.save_pretrained(tokenizer_path)\n",
    "print(f\"Model saved at : {new_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()  # release CUDA memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
