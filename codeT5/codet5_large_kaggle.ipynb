{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U transformers datasets accelerate evaluate huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:23:09.917659Z","iopub.execute_input":"2024-09-15T18:23:09.918015Z","iopub.status.idle":"2024-09-15T18:23:39.299394Z","shell.execute_reply.started":"2024-09-15T18:23:09.917978Z","shell.execute_reply":"2024-09-15T18:23:39.298383Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nCollecting transformers\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nCollecting datasets\n  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.33.0)\nCollecting accelerate\n  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.24.6)\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading datasets-3.0.0-py3-none-any.whl (474 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface_hub, accelerate, transformers, datasets, evaluate\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.24.6\n    Uninstalling huggingface-hub-0.24.6:\n      Successfully uninstalled huggingface-hub-0.24.6\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.33.0\n    Uninstalling accelerate-0.33.0:\n      Successfully uninstalled accelerate-0.33.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.0\n    Uninstalling transformers-4.44.0:\n      Successfully uninstalled transformers-4.44.0\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.21.0\n    Uninstalling datasets-2.21.0:\n      Successfully uninstalled datasets-2.21.0\nSuccessfully installed accelerate-0.34.2 datasets-3.0.0 evaluate-0.4.3 huggingface_hub-0.24.7 transformers-4.44.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\nimport logging\nimport transformers\nfrom evaluate import load\nfrom torch.optim import AdamW\nfrom huggingface_hub import login\nfrom datasets import load_dataset\nfrom accelerate import Accelerator\nfrom torch.utils.data import DataLoader\nfrom transformers import (\n    RobertaTokenizer,\n    T5ForConditionalGeneration,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n    DataCollatorForSeq2Seq\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:23:39.301255Z","iopub.execute_input":"2024-09-15T18:23:39.301565Z","iopub.status.idle":"2024-09-15T18:23:58.287164Z","shell.execute_reply.started":"2024-09-15T18:23:39.301531Z","shell.execute_reply":"2024-09-15T18:23:58.286360Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Define Variables","metadata":{}},{"cell_type":"code","source":"base_model = \"Salesforce/codet5-large\"\n\nnew_model = \"CODEX-codet5-large\"\n\ntokenizer_path = \"tokenizer\"\n\ndataset_name = \"CodexAI/Deepseek-Coder\"","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:23:58.288321Z","iopub.execute_input":"2024-09-15T18:23:58.288924Z","iopub.status.idle":"2024-09-15T18:23:58.293614Z","shell.execute_reply.started":"2024-09-15T18:23:58.288890Z","shell.execute_reply":"2024-09-15T18:23:58.292562Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"login('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',add_to_git_credential=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:23:58.296345Z","iopub.execute_input":"2024-09-15T18:23:58.296755Z","iopub.status.idle":"2024-09-15T18:23:58.568373Z","shell.execute_reply.started":"2024-09-15T18:23:58.296706Z","shell.execute_reply":"2024-09-15T18:23:58.567398Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Token is valid (permission: write).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset\nLoad the dataset using `load_dataset()` but the dataset must be in `.parquet` format.\nor else clone the dataset repo from HF, it's fast as fuck!","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(dataset_name)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:23:58.569643Z","iopub.execute_input":"2024-09-15T18:23:58.570000Z","iopub.status.idle":"2024-09-15T18:24:02.661712Z","shell.execute_reply.started":"2024-09-15T18:23:58.569965Z","shell.execute_reply":"2024-09-15T18:24:02.660826Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/421 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"310f5b1fcedb496fadb5fa2583702dd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/61.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9058f242b9bb48859298c65dbba5e7c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/2.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c8e99202e0d4199b3158996019bbb91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/75000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f2c5fd12ec044e784ecbc93d6f1212a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3534 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daef5957a7b84b26880ad04075d061b2"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['instruction', 'output'],\n        num_rows: 75000\n    })\n    test: Dataset({\n        features: ['instruction', 'output'],\n        num_rows: 3534\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Playing with Dataset","metadata":{}},{"cell_type":"code","source":"train=dataset['train']\ntrain","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:02.663104Z","iopub.execute_input":"2024-09-15T18:24:02.663725Z","iopub.status.idle":"2024-09-15T18:24:02.673433Z","shell.execute_reply.started":"2024-09-15T18:24:02.663680Z","shell.execute_reply":"2024-09-15T18:24:02.672420Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'output'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"test=dataset['test']\ntest","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:02.674623Z","iopub.execute_input":"2024-09-15T18:24:02.675077Z","iopub.status.idle":"2024-09-15T18:24:02.687002Z","shell.execute_reply.started":"2024-09-15T18:24:02.675035Z","shell.execute_reply":"2024-09-15T18:24:02.686156Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'output'],\n    num_rows: 3534\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Inspecting dataset instance\nHere dataset instance is printed just to see how the dataset looks like, skip these steps if your are **gay**","metadata":{}},{"cell_type":"code","source":"print(train['instruction'][0])","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:02.688161Z","iopub.execute_input":"2024-09-15T18:24:02.688539Z","iopub.status.idle":"2024-09-15T18:24:02.699827Z","shell.execute_reply.started":"2024-09-15T18:24:02.688495Z","shell.execute_reply":"2024-09-15T18:24:02.698992Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Generate a unit test case for the following Java method: EhCoversFF extends GenericFilterFunction { @Override protected boolean relate(GeometryWrapper sourceGeometry, GeometryWrapper targetGeometry) throws FactoryException, MismatchedDimensionException, TransformException { return sourceGeometry.relate(targetGeometry, EgenhoferIntersectionPattern.COVERS); }  @Override boolean isDisjoint(); @Override boolean isDisconnected();  }\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train['output'][0])","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:02.700982Z","iopub.execute_input":"2024-09-15T18:24:02.701342Z","iopub.status.idle":"2024-09-15T18:24:02.712269Z","shell.execute_reply.started":"2024-09-15T18:24:02.701301Z","shell.execute_reply":"2024-09-15T18:24:02.711435Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"The unit test case for the given Java method is: @Test public void testRelate_polygon_polygon_false() throws FactoryException, MismatchedDimensionException, TransformException { GeometryWrapper subjectGeometryWrapper = GeometryWrapper.extract(ResourceFactory.createTypedLiteral(\"<http: GeometryWrapper objectGeometryWrapper = GeometryWrapper.extract(ResourceFactory.createTypedLiteral(\"<http: EhCoversFF instance = new EhCoversFF(); Boolean expResult = false; Boolean result = instance.relate(subjectGeometryWrapper, objectGeometryWrapper); assertEquals(expResult, result); }\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Loading tokenizer...\")\ntokenizer = RobertaTokenizer.from_pretrained(base_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:02.715522Z","iopub.execute_input":"2024-09-15T18:24:02.715807Z","iopub.status.idle":"2024-09-15T18:24:04.365157Z","shell.execute_reply.started":"2024-09-15T18:24:02.715778Z","shell.execute_reply":"2024-09-15T18:24:04.364185Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Loading tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a56235db51c4b0abf713c4a4e01b6fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/511k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c000de6256f422c94e6315ba199e92a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/294k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82c4f43190c045a292436342c4b6d63d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/11.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3afad34e9094e0bb88651f086cf10e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2cc98280434474ca51c83cc98a3442b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"instruction = tokenizer(train['instruction'][0])\ninstruction","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:04.366310Z","iopub.execute_input":"2024-09-15T18:24:04.366632Z","iopub.status.idle":"2024-09-15T18:24:04.380219Z","shell.execute_reply.started":"2024-09-15T18:24:04.366599Z","shell.execute_reply":"2024-09-15T18:24:04.379350Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [1, 4625, 279, 2836, 1842, 648, 364, 326, 3751, 5110, 707, 30, 512, 76, 39, 23042, 2246, 3231, 7928, 1586, 2083, 288, 632, 6618, 4750, 1250, 1279, 340, 12, 9823, 3611, 1084, 9823, 16, 8344, 3611, 1018, 9823, 13, 1216, 7822, 503, 16, 26454, 8611, 503, 16, 11514, 503, 288, 327, 1084, 9823, 18, 2878, 340, 12, 3299, 9823, 16, 512, 4507, 15008, 586, 23634, 3234, 18, 3865, 21510, 1769, 289, 225, 632, 6618, 1250, 353, 1669, 16452, 5621, 632, 6618, 1250, 353, 26303, 5621, 225, 289, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"tokens = tokenizer.convert_ids_to_tokens(instruction.input_ids)\ntokens","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:04.381511Z","iopub.execute_input":"2024-09-15T18:24:04.381915Z","iopub.status.idle":"2024-09-15T18:24:04.389393Z","shell.execute_reply.started":"2024-09-15T18:24:04.381882Z","shell.execute_reply":"2024-09-15T18:24:04.388348Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['<s>',\n 'Generate',\n 'Ġa',\n 'Ġunit',\n 'Ġtest',\n 'Ġcase',\n 'Ġfor',\n 'Ġthe',\n 'Ġfollowing',\n 'ĠJava',\n 'Ġmethod',\n ':',\n 'ĠE',\n 'h',\n 'C',\n 'overs',\n 'FF',\n 'Ġextends',\n 'ĠGeneric',\n 'Filter',\n 'Function',\n 'Ġ{',\n 'Ġ@',\n 'Override',\n 'Ġprotected',\n 'Ġboolean',\n 'Ġrel',\n 'ate',\n '(',\n 'Geometry',\n 'Wrapper',\n 'Ġsource',\n 'Geometry',\n ',',\n 'ĠGeometry',\n 'Wrapper',\n 'Ġtarget',\n 'Geometry',\n ')',\n 'Ġthrows',\n 'ĠFactory',\n 'Exception',\n ',',\n 'ĠMismatched',\n 'Dimension',\n 'Exception',\n ',',\n 'ĠTransform',\n 'Exception',\n 'Ġ{',\n 'Ġreturn',\n 'Ġsource',\n 'Geometry',\n '.',\n 'rel',\n 'ate',\n '(',\n 'target',\n 'Geometry',\n ',',\n 'ĠE',\n 'gen',\n 'ho',\n 'fer',\n 'Intersection',\n 'Pattern',\n '.',\n 'CO',\n 'VERS',\n ');',\n 'Ġ}',\n 'Ġ',\n 'Ġ@',\n 'Override',\n 'Ġboolean',\n 'Ġis',\n 'Dis',\n 'joint',\n '();',\n 'Ġ@',\n 'Override',\n 'Ġboolean',\n 'Ġis',\n 'Disconnected',\n '();',\n 'Ġ',\n 'Ġ}',\n '</s>']"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.convert_tokens_to_string(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:04.390524Z","iopub.execute_input":"2024-09-15T18:24:04.391190Z","iopub.status.idle":"2024-09-15T18:24:04.399880Z","shell.execute_reply.started":"2024-09-15T18:24:04.391147Z","shell.execute_reply":"2024-09-15T18:24:04.398973Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'<s>Generate a unit test case for the following Java method: EhCoversFF extends GenericFilterFunction { @Override protected boolean relate(GeometryWrapper sourceGeometry, GeometryWrapper targetGeometry) throws FactoryException, MismatchedDimensionException, TransformException { return sourceGeometry.relate(targetGeometry, EgenhoferIntersectionPattern.COVERS); }  @Override boolean isDisjoint(); @Override boolean isDisconnected();  }</s>'"},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Vocab size : {tokenizer.vocab_size}\")\nprint(f\"max length : {tokenizer.model_max_length}\")\nprint(f\"model input : {tokenizer.model_input_names}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:04.400905Z","iopub.execute_input":"2024-09-15T18:24:04.401203Z","iopub.status.idle":"2024-09-15T18:24:04.408318Z","shell.execute_reply.started":"2024-09-15T18:24:04.401173Z","shell.execute_reply":"2024-09-15T18:24:04.407339Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Vocab size : 32100\nmax length : 512\nmodel input : ['input_ids', 'attention_mask']\n","output_type":"stream"}]},{"cell_type":"code","source":"batch = tokenizer(train['instruction'][0],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\nbatch","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:04.409548Z","iopub.execute_input":"2024-09-15T18:24:04.409897Z","iopub.status.idle":"2024-09-15T18:24:04.471976Z","shell.execute_reply.started":"2024-09-15T18:24:04.409857Z","shell.execute_reply":"2024-09-15T18:24:04.471109Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[    1,  4625,   279,  2836,  1842,   648,   364,   326,  3751,  5110,\n           707,    30,   512,    76,    39, 23042,  2246,  3231,  7928,  1586,\n          2083,   288,   632,  6618,  4750,  1250,  1279,   340,    12,  9823,\n          3611,  1084,  9823,    16,  8344,  3611,  1018,  9823,    13,  1216,\n          7822,   503,    16, 26454,  8611,   503,    16, 11514,   503,   288,\n           327,  1084,  9823,    18,  2878,   340,    12,  3299,  9823,    16,\n           512,  4507, 15008,   586, 23634,  3234,    18,  3865, 21510,  1769,\n           289,   225,   632,  6618,  1250,   353,  1669, 16452,  5621,   632,\n          6618,  1250,   353, 26303,  5621,   225,   289,     2,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]])}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenizing Dataset","metadata":{}},{"cell_type":"code","source":"def tokenize_data(data):\n  input_col=tokenizer(data['instruction'],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n  target_col=tokenizer(data['output'],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n\n  return {\n      \"input_ids\":input_col[\"input_ids\"],\n      \"attention_mask\":input_col[\"attention_mask\"],\n      \"labels\":target_col[\"input_ids\"]\n  }","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:04.473053Z","iopub.execute_input":"2024-09-15T18:24:04.473354Z","iopub.status.idle":"2024-09-15T18:24:04.478703Z","shell.execute_reply.started":"2024-09-15T18:24:04.473323Z","shell.execute_reply":"2024-09-15T18:24:04.477754Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(\"Tokenizing dataset...\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:04.480044Z","iopub.execute_input":"2024-09-15T18:24:04.480361Z","iopub.status.idle":"2024-09-15T18:24:04.489614Z","shell.execute_reply.started":"2024-09-15T18:24:04.480330Z","shell.execute_reply":"2024-09-15T18:24:04.488791Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Tokenizing dataset...\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Mapping train data...\")\ntrain=train.map(tokenize_data,batched=True)\ntrain","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:04.490704Z","iopub.execute_input":"2024-09-15T18:24:04.491024Z","iopub.status.idle":"2024-09-15T18:24:15.764740Z","shell.execute_reply.started":"2024-09-15T18:24:04.490993Z","shell.execute_reply":"2024-09-15T18:24:15.763833Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Mapping train data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd18286138d84df2ac49ba4fc2368b41"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'output', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Mappig test data...\")\ntest=test.map(tokenize_data,batched=True)\ntest","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:15.766163Z","iopub.execute_input":"2024-09-15T18:24:15.766472Z","iopub.status.idle":"2024-09-15T18:24:46.893278Z","shell.execute_reply.started":"2024-09-15T18:24:15.766439Z","shell.execute_reply":"2024-09-15T18:24:46.892328Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Mappig test data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3534 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7939eaeffdc2458e9897bf2f6f79be90"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'output', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 3534\n})"},"metadata":{}}]},{"cell_type":"code","source":"train=train.remove_columns([\"instruction\",\"output\"])\ntest=test.remove_columns([\"instruction\",\"output\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:46.894477Z","iopub.execute_input":"2024-09-15T18:24:46.894794Z","iopub.status.idle":"2024-09-15T18:24:46.903585Z","shell.execute_reply.started":"2024-09-15T18:24:46.894762Z","shell.execute_reply":"2024-09-15T18:24:46.902599Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:46.904752Z","iopub.execute_input":"2024-09-15T18:24:46.905221Z","iopub.status.idle":"2024-09-15T18:24:46.970876Z","shell.execute_reply.started":"2024-09-15T18:24:46.905177Z","shell.execute_reply":"2024-09-15T18:24:46.969953Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"# train = train.select(range(1000))  # seleting 1k dataset, you dont have to\n# print(train)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:46.972256Z","iopub.execute_input":"2024-09-15T18:24:46.972595Z","iopub.status.idle":"2024-09-15T18:24:46.979258Z","shell.execute_reply.started":"2024-09-15T18:24:46.972561Z","shell.execute_reply":"2024-09-15T18:24:46.978383Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Fine-tuning","metadata":{}},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return f'trainable model parameters: {trainable_model_params}\\n \\\n            all model parameters: {all_model_params} \\n \\\n            percentage of trainable model parameters: {(trainable_model_params / all_model_params) * 100} %'","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:46.980276Z","iopub.execute_input":"2024-09-15T18:24:46.980579Z","iopub.status.idle":"2024-09-15T18:24:46.990210Z","shell.execute_reply.started":"2024-09-15T18:24:46.980547Z","shell.execute_reply":"2024-09-15T18:24:46.989329Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n    device={\"\":0}\n    torch_type=torch.bfloat16\nelse:\n    device=\"cpu\"\n    torch_type=torch.bfloat16\n    print(\"I am begging for mercy already!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:46.991241Z","iopub.execute_input":"2024-09-15T18:24:46.991499Z","iopub.status.idle":"2024-09-15T18:24:47.048068Z","shell.execute_reply.started":"2024-09-15T18:24:46.991468Z","shell.execute_reply":"2024-09-15T18:24:47.047144Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"CUDA device: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"BF16 support is {transformers.utils.import_utils.is_torch_bf16_gpu_available()}\")   # must check","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:47.049288Z","iopub.execute_input":"2024-09-15T18:24:47.049663Z","iopub.status.idle":"2024-09-15T18:24:47.185461Z","shell.execute_reply.started":"2024-09-15T18:24:47.049620Z","shell.execute_reply":"2024-09-15T18:24:47.184498Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"BF16 support is True\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ[\"ACCELERATE_MIXED_PRECISION\"] = \"bf16\"\nos.environ[\"ACCELERATE_GRADIENT_ACCUMULATION_STEPS\"] = \"4\"\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:47.186953Z","iopub.execute_input":"2024-09-15T18:24:47.187462Z","iopub.status.idle":"2024-09-15T18:24:47.192318Z","shell.execute_reply.started":"2024-09-15T18:24:47.187415Z","shell.execute_reply":"2024-09-15T18:24:47.191410Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Loading base model","metadata":{}},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(base_model,device_map=device)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:47.193452Z","iopub.execute_input":"2024-09-15T18:24:47.193738Z","iopub.status.idle":"2024-09-15T18:24:56.386220Z","shell.execute_reply.started":"2024-09-15T18:24:47.193707Z","shell.execute_reply":"2024-09-15T18:24:56.385396Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c435289295442ccadc227dfc053b794"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.48G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76d9cf9bfe354707b3292ac3071ad228"}},"metadata":{}}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:56.393609Z","iopub.execute_input":"2024-09-15T18:24:56.394336Z","iopub.status.idle":"2024-09-15T18:24:56.405609Z","shell.execute_reply.started":"2024-09-15T18:24:56.394289Z","shell.execute_reply":"2024-09-15T18:24:56.404711Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"T5ForConditionalGeneration(\n  (shared): Embedding(32100, 1024)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32100, 1024)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n              (relative_attention_bias): Embedding(32, 16)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-23): 23 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32100, 1024)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n              (relative_attention_bias): Embedding(32, 16)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-23): 23 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=1024, out_features=32100, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(print_number_of_trainable_model_parameters(model))","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:56.406813Z","iopub.execute_input":"2024-09-15T18:24:56.407110Z","iopub.status.idle":"2024-09-15T18:24:56.422202Z","shell.execute_reply.started":"2024-09-15T18:24:56.407078Z","shell.execute_reply":"2024-09-15T18:24:56.421352Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"trainable model parameters: 737639424\n             all model parameters: 737639424 \n             percentage of trainable model parameters: 100.0 %\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## LoRA Config for PEFT","metadata":{}},{"cell_type":"code","source":"# lora_config = LoraConfig(\n#     r=32,  # rank 16,32,64\n#     lora_alpha=16, # LoRA Scaling factor keep 16 or 32\n#     target_modules=['q', 'v'], # The modules(for example, attention blocks) to apply the LoRA update matrices.\n#     lora_dropout = 0.1, # 0.05\n#     bias='none',\n#     task_type=TaskType.SEQ_2_SEQ_LM ## flan-t5\n# )","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:56.423317Z","iopub.execute_input":"2024-09-15T18:24:56.423659Z","iopub.status.idle":"2024-09-15T18:24:56.432164Z","shell.execute_reply.started":"2024-09-15T18:24:56.423626Z","shell.execute_reply":"2024-09-15T18:24:56.431378Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# peft_model = get_peft_model(model, lora_config)\n# print(peft_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:56.433283Z","iopub.execute_input":"2024-09-15T18:24:56.433600Z","iopub.status.idle":"2024-09-15T18:24:56.442295Z","shell.execute_reply.started":"2024-09-15T18:24:56.433568Z","shell.execute_reply":"2024-09-15T18:24:56.441532Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# print(print_number_of_trainable_model_parameters(peft_model))","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:56.443825Z","iopub.execute_input":"2024-09-15T18:24:56.444206Z","iopub.status.idle":"2024-09-15T18:24:56.452640Z","shell.execute_reply.started":"2024-09-15T18:24:56.444164Z","shell.execute_reply":"2024-09-15T18:24:56.451818Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Training args","metadata":{}},{"cell_type":"code","source":"# training_args = Seq2SeqTrainingArguments(\n#     output_dir=\"./results\",\n#     run_name =\"./loggings\",\n#     overwrite_output_dir=True,\n#     eval_strategy=\"steps\",\n#     learning_rate=1e-4,\n#     gradient_accumulation_steps=4,\n#     per_device_train_batch_size=2,\n#     per_device_eval_batch_size=1,\n#     weight_decay=0.01,\n#     num_train_epochs=1,\n#     bf16=True,  # Switching to FP16, BF16 = True on kaggle\n#     optim=\"adamw_torch\",\n#     save_strategy=\"no\",\n#     log_level=\"info\",\n#     logging_first_step=True,\n#     report_to='none'\n# )","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:56.454586Z","iopub.execute_input":"2024-09-15T18:24:56.454888Z","iopub.status.idle":"2024-09-15T18:24:56.462223Z","shell.execute_reply.started":"2024-09-15T18:24:56.454856Z","shell.execute_reply":"2024-09-15T18:24:56.461360Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(\n    tokenizer, \n    model=model\n#     model=peft_model \n)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:26:59.485070Z","iopub.execute_input":"2024-09-15T18:26:59.485764Z","iopub.status.idle":"2024-09-15T18:26:59.490090Z","shell.execute_reply.started":"2024-09-15T18:26:59.485724Z","shell.execute_reply":"2024-09-15T18:26:59.489005Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# trainer=Seq2SeqTrainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=train,\n#     eval_dataset=test,\n#     data_collator=data_collator\n# )","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:56.476676Z","iopub.execute_input":"2024-09-15T18:24:56.476985Z","iopub.status.idle":"2024-09-15T18:24:56.484753Z","shell.execute_reply.started":"2024-09-15T18:24:56.476946Z","shell.execute_reply":"2024-09-15T18:24:56.483870Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(\"Starting trainer...\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:56.486048Z","iopub.execute_input":"2024-09-15T18:24:56.487016Z","iopub.status.idle":"2024-09-15T18:24:56.494398Z","shell.execute_reply.started":"2024-09-15T18:24:56.486970Z","shell.execute_reply":"2024-09-15T18:24:56.493529Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Starting trainer...\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:56.495525Z","iopub.execute_input":"2024-09-15T18:24:56.495811Z","iopub.status.idle":"2024-09-15T18:24:57.598498Z","shell.execute_reply.started":"2024-09-15T18:24:56.495781Z","shell.execute_reply":"2024-09-15T18:24:57.597317Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Sun Sep 15 18:24:57 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0             32W /  250W |    3211MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### start fine-tuning with `trainer.train()`","metadata":{}},{"cell_type":"code","source":"# trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:57.600196Z","iopub.execute_input":"2024-09-15T18:24:57.601084Z","iopub.status.idle":"2024-09-15T18:24:57.605639Z","shell.execute_reply.started":"2024-09-15T18:24:57.601036Z","shell.execute_reply":"2024-09-15T18:24:57.604627Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### or you can go with `Accelerator`","metadata":{}},{"cell_type":"code","source":"logging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:24:57.607461Z","iopub.execute_input":"2024-09-15T18:24:57.607843Z","iopub.status.idle":"2024-09-15T18:24:57.633429Z","shell.execute_reply.started":"2024-09-15T18:24:57.607799Z","shell.execute_reply":"2024-09-15T18:24:57.632487Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"accelerator = Accelerator()\n\noptimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n\ntrain_dataloader = DataLoader(train, batch_size=1, shuffle=True, collate_fn=data_collator)\neval_dataloader = DataLoader(test, batch_size=1, collate_fn=data_collator)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:27:07.999620Z","iopub.execute_input":"2024-09-15T18:27:08.000466Z","iopub.status.idle":"2024-09-15T18:27:08.012954Z","shell.execute_reply.started":"2024-09-15T18:27:08.000423Z","shell.execute_reply":"2024-09-15T18:27:08.012076Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n    model, optimizer, train_dataloader, eval_dataloader\n)\nepochs = 1","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:27:09.050966Z","iopub.execute_input":"2024-09-15T18:27:09.051842Z","iopub.status.idle":"2024-09-15T18:27:09.085833Z","shell.execute_reply.started":"2024-09-15T18:27:09.051802Z","shell.execute_reply":"2024-09-15T18:27:09.085081Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"logger.info(\"***** Running training *****\")\nlogger.info(f\"  Num examples = {len(train_dataloader.dataset)}\")\nlogger.info(f\"  Num Epochs = 1\")\nlogger.info(f\"  Total optimization steps = {len(train_dataloader)}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:27:10.328902Z","iopub.execute_input":"2024-09-15T18:27:10.329343Z","iopub.status.idle":"2024-09-15T18:27:10.335234Z","shell.execute_reply.started":"2024-09-15T18:27:10.329303Z","shell.execute_reply":"2024-09-15T18:27:10.334193Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    logger.info(f\"Starting epoch {epoch + 1}\")\n    model.train()\n\n    for step, batch in enumerate(train_dataloader):\n        outputs = model(**batch)\n        loss = outputs.loss\n        accelerator.backward(loss)  # Backpropagation, accelerator will take care of it\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if step % 10 == 0:  # Log every 10 steps\n            logger.info(f\"Epoch: {epoch + 1}, Step: {step}, Loss: {loss.item()}\")\n\n    # Evaluation loop (optional)\n    total_eval_loss = 0\n    model.eval()\n    for step, batch in enumerate(eval_dataloader):\n        with torch.no_grad():\n            outputs = model(**batch)\n            eval_loss = outputs.loss\n            total_eval_loss += eval_loss.item()\n\n        # Logging at each evaluation step\n        if step % 10 == 0:\n            logger.info(f\"Evaluation Step: {step}, Eval Loss: {eval_loss.item()}\")\n\n    avg_eval_loss = total_eval_loss / len(eval_dataloader)\n    logger.info(f\"Epoch {epoch + 1} Evaluation Complete. Average Eval Loss: {avg_eval_loss}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:27:11.693386Z","iopub.execute_input":"2024-09-15T18:27:11.693788Z","iopub.status.idle":"2024-09-15T18:40:14.923820Z","shell.execute_reply.started":"2024-09-15T18:27:11.693749Z","shell.execute_reply":"2024-09-15T18:40:14.922664Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"print(\"finished. Saving model...\")\nmodel.save_pretrained(new_model)\ntokenizer.save_pretrained(tokenizer_path)\nprint(f\"Model saved at : {new_model}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:46:48.624945Z","iopub.execute_input":"2024-09-15T18:46:48.625986Z","iopub.status.idle":"2024-09-15T18:46:54.879542Z","shell.execute_reply.started":"2024-09-15T18:46:48.625937Z","shell.execute_reply":"2024-09-15T18:46:54.878487Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"finished. Saving model...\nModel saved at : CODEX-codet5-large\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:46:58.640684Z","iopub.execute_input":"2024-09-15T18:46:58.641093Z","iopub.status.idle":"2024-09-15T18:46:58.645696Z","shell.execute_reply.started":"2024-09-15T18:46:58.641056Z","shell.execute_reply":"2024-09-15T18:46:58.644805Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Load model amd tokenier\nmodel = T5ForConditionalGeneration.from_pretrained(new_model).to(device)\ntokenizer = RobertaTokenizer.from_pretrained(tokenizer_path,device=device)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:47:02.853877Z","iopub.execute_input":"2024-09-15T18:47:02.854783Z","iopub.status.idle":"2024-09-15T18:47:05.084293Z","shell.execute_reply.started":"2024-09-15T18:47:02.854745Z","shell.execute_reply":"2024-09-15T18:47:05.083453Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:47:05.237669Z","iopub.execute_input":"2024-09-15T18:47:05.238221Z","iopub.status.idle":"2024-09-15T18:47:05.252573Z","shell.execute_reply.started":"2024-09-15T18:47:05.238173Z","shell.execute_reply":"2024-09-15T18:47:05.251674Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32100, 1024)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32100, 1024)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n              (relative_attention_bias): Embedding(32, 16)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-23): 23 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32100, 1024)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n              (relative_attention_bias): Embedding(32, 16)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-23): 23 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=1024, out_features=1024, bias=False)\n              (k): Linear(in_features=1024, out_features=1024, bias=False)\n              (v): Linear(in_features=1024, out_features=1024, bias=False)\n              (o): Linear(in_features=1024, out_features=1024, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=1024, out_features=4096, bias=False)\n              (wo): Linear(in_features=4096, out_features=1024, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=1024, out_features=32100, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def generate_unit_tests(instruction):\n    \n  inputs = tokenizer(instruction, max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n  inputs = {key: value.to(device) for key, value in inputs.items()}\n\n  outputs = model.generate(\n      input_ids=inputs[\"input_ids\"],\n      attention_mask=inputs[\"attention_mask\"],\n      max_length=512,\n      num_beams=5,\n      do_sample=True,  # Enable sampling for diverse output\n      temperature=0.7,  # Control randomness\n      top_k=100,  # Limit the sampling pool to top K tokens\n      top_p=0.9,\n      no_repeat_ngram_size=5,\n      repetition_penalty=1.5,\n      length_penalty=1.0,\n      early_stopping=True\n  )\n\n  # Decode the generated output\n  generated_test = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n  return generated_test","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:47:06.752061Z","iopub.execute_input":"2024-09-15T18:47:06.752948Z","iopub.status.idle":"2024-09-15T18:47:06.796624Z","shell.execute_reply.started":"2024-09-15T18:47:06.752888Z","shell.execute_reply":"2024-09-15T18:47:06.795698Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"instruction = \"\"\"\npublic class SimpleCalculator {\n    // Method to add two numbers\n    public int add(int a, int b) {\n        return a + b;\n    }\n\n    // Method to subtract two numbers\n    public int subtract(int a, int b) {\n        return a - b;\n    }\n\n    // Method to multiply two numbers\n    public int multiply(int a, int b) {\n        return a * b;\n    }\n\n    // Method to divide two numbers\n    // Throws ArithmeticException if divisor is zero\n    public double divide(int a, int b) {\n        if (b == 0) {\n            throw new ArithmeticException(\"Cannot divide by zero\");\n        }\n        return (double) a / b;\n    }\n}\n\"\"\"\nprompt=\"Generate a unit test case for the following Java method: \"+instruction\n# print(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:47:07.764529Z","iopub.execute_input":"2024-09-15T18:47:07.766001Z","iopub.status.idle":"2024-09-15T18:47:08.676456Z","shell.execute_reply.started":"2024-09-15T18:47:07.765949Z","shell.execute_reply":"2024-09-15T18:47:08.675385Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"generated_test = generate_unit_tests(prompt)\nprint(generated_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:47:08.778818Z","iopub.execute_input":"2024-09-15T18:47:08.779260Z","iopub.status.idle":"2024-09-15T18:47:17.403620Z","shell.execute_reply.started":"2024-09-15T18:47:08.779219Z","shell.execute_reply":"2024-09-15T18:47:17.402729Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"The unit test case for the given Java method is: @Test public void testDivide() throws ArithmeticException { int i = 0; int i = 1; int i = 2; int i = 3; int i = 4; int i = 6; int i = 7; int i = 5; int i = 10; int i = 15; int i = -1; int i = 29; int i = 30; int i = 31; int i = 27; int i = 52; int i = 40; int i = 60; int i = 70; int i = 75; int i = 50; int i = 20; int i = 25; int i = 28; int i = Integer.MAX_VALUE; int i = (int) Math.max(i, i); Assert.assertEquals(2, i); }\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Push to HF","metadata":{}},{"cell_type":"code","source":"repo_name = new_model\nrepo_url = f\"CodexAI/{repo_name}\"","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:49:13.707623Z","iopub.execute_input":"2024-09-15T18:49:13.708784Z","iopub.status.idle":"2024-09-15T18:49:13.712669Z","shell.execute_reply.started":"2024-09-15T18:49:13.708741Z","shell.execute_reply":"2024-09-15T18:49:13.711780Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"### use the `push_to_hub()` , but its shit","metadata":{}},{"cell_type":"code","source":"model.push_to_hub(repo_url, private=True)\ntokenizer.push_to_hub(repo_url, private=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:49:30.151166Z","iopub.execute_input":"2024-09-15T18:49:30.151612Z","iopub.status.idle":"2024-09-15T18:51:09.797602Z","shell.execute_reply.started":"2024-09-15T18:49:30.151570Z","shell.execute_reply":"2024-09-15T18:51:09.796289Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d948a049cd20498cb5be6e9356ace965"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2cab8e6d3c745f6b31d53aef498a5c4"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mpush_to_hub(repo_url, private\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:930\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m files_timestamps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_files_timestamps(work_dir)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;66;03m# Save all files.\u001b[39;00m\n\u001b[0;32m--> 930\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_shard_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_serialization\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m# Update model card if needed:\u001b[39;00m\n\u001b[1;32m    933\u001b[0m model_card\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(work_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2682\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.save_pretrained\u001b[0;34m(self, save_directory, legacy_format, filename_prefix, push_to_hub, **kwargs)\u001b[0m\n\u001b[1;32m   2679\u001b[0m     tokenizer_config\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_map\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tokenizer_config_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m-> 2682\u001b[0m     out_str \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2683\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(out_str)\n\u001b[1;32m   2684\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer config file saved in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_config_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:201\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterencode(o, _one_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunks)\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 431\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 438\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: Object of type device is not JSON serializable"],"ename":"TypeError","evalue":"Object of type device is not JSON serializable","output_type":"error"}]},{"cell_type":"markdown","source":"### use the `HfApi` which is recomended","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import HfApi, create_repo","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:51:26.140153Z","iopub.execute_input":"2024-09-15T18:51:26.141067Z","iopub.status.idle":"2024-09-15T18:51:26.145580Z","shell.execute_reply.started":"2024-09-15T18:51:26.141021Z","shell.execute_reply":"2024-09-15T18:51:26.144474Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"create_repo(repo_url, repo_type=\"model\", private=True,exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:51:27.118126Z","iopub.execute_input":"2024-09-15T18:51:27.118999Z","iopub.status.idle":"2024-09-15T18:51:27.220284Z","shell.execute_reply.started":"2024-09-15T18:51:27.118949Z","shell.execute_reply":"2024-09-15T18:51:27.219336Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"RepoUrl('https://huggingface.co/CodexAI/CODEX-codet5-large', endpoint='https://huggingface.co', repo_type='model', repo_id='CodexAI/CODEX-codet5-large')"},"metadata":{}}]},{"cell_type":"code","source":"api = HfApi()\napi.upload_folder(folder_path=new_model,repo_id=repo_url)","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:51:29.369489Z","iopub.execute_input":"2024-09-15T18:51:29.370324Z","iopub.status.idle":"2024-09-15T18:51:38.037978Z","shell.execute_reply.started":"2024-09-15T18:51:29.370285Z","shell.execute_reply":"2024-09-15T18:51:38.037076Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/CodexAI/CODEX-codet5-large/commit/5fa1270232498d5e84c3b4f4efc5d1cf6adc7095', commit_message='Upload folder using huggingface_hub', commit_description='', oid='5fa1270232498d5e84c3b4f4efc5d1cf6adc7095', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Model and Tokenizer saved at {repo_url}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:51:38.039869Z","iopub.execute_input":"2024-09-15T18:51:38.040530Z","iopub.status.idle":"2024-09-15T18:51:38.045537Z","shell.execute_reply.started":"2024-09-15T18:51:38.040486Z","shell.execute_reply":"2024-09-15T18:51:38.044672Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Model and Tokenizer saved at CodexAI/CODEX-codet5-large\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.empty_cache()    # release CUDA","metadata":{"execution":{"iopub.status.busy":"2024-09-15T18:51:38.046564Z","iopub.execute_input":"2024-09-15T18:51:38.046857Z","iopub.status.idle":"2024-09-15T18:51:38.214185Z","shell.execute_reply.started":"2024-09-15T18:51:38.046825Z","shell.execute_reply":"2024-09-15T18:51:38.213318Z"},"trusted":true},"execution_count":59,"outputs":[]}]}