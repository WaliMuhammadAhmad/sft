{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-04T11:58:01.199561Z","iopub.status.busy":"2024-09-04T11:58:01.199235Z","iopub.status.idle":"2024-09-04T11:58:35.380301Z","shell.execute_reply":"2024-09-04T11:58:35.378963Z","shell.execute_reply.started":"2024-09-04T11:58:01.199527Z"},"trusted":true},"outputs":[],"source":["# %%capture\n","# %pip install -U accelerate peft bitsandbytes transformers trl evaluate attrdict tqdm datasets\n","# --OR--\n","# %%capture\n","# %pip install -r requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T11:58:35.383030Z","iopub.status.busy":"2024-09-04T11:58:35.382624Z","iopub.status.idle":"2024-09-04T11:58:55.214036Z","shell.execute_reply":"2024-09-04T11:58:55.213204Z","shell.execute_reply.started":"2024-09-04T11:58:35.382985Z"},"trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with 'env (Python 3.12.5)' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: 'd:/FYP/CODEX-FINETUNNING/deepseek-coder/env/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"]}],"source":["import os\n","import torch\n","import json\n","import shutil\n","import transformers\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n",")\n","from peft import (\n","    LoraConfig,\n","    get_peft_model,\n","    TaskType,\n","    PeftModel, \n","    PeftConfig\n",")\n","from evaluate import load\n","from trl import SFTTrainer\n","from datasets import Dataset, load_dataset\n","from huggingface_hub import login, Repository"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:00:24.705464Z","iopub.status.busy":"2024-09-04T12:00:24.704677Z","iopub.status.idle":"2024-09-04T12:00:24.711009Z","shell.execute_reply":"2024-09-04T12:00:24.709892Z","shell.execute_reply.started":"2024-09-04T12:00:24.705422Z"},"trusted":true},"outputs":[],"source":["model = \"deepseek-coder-1.3b-instruct\"  # model to be fine-tuned\n","\n","base_model = f\"deepseek-ai/{model}\" \n","\n","new_model = f\"CODEX-{model}\"  # fine-tunned model name\n","\n","dataset_path = \"dataset\"  # dataset dir path\n","\n","dataset = \"CodexAI/Deepseek-Coder\"  # dataset name at huggingface\n","\n","repo_url = f'https://huggingface.co/datasets/{dataset}'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["login('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',add_to_git_credential=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:00:46.062348Z","iopub.status.busy":"2024-09-04T12:00:46.061461Z","iopub.status.idle":"2024-09-04T12:00:46.066480Z","shell.execute_reply":"2024-09-04T12:00:46.065352Z","shell.execute_reply.started":"2024-09-04T12:00:46.062308Z"},"trusted":true},"outputs":[],"source":["repo = Repository(local_dir=dataset_path,clone_from=repo_url)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:00:53.442188Z","iopub.status.busy":"2024-09-04T12:00:53.441361Z","iopub.status.idle":"2024-09-04T12:00:53.448399Z","shell.execute_reply":"2024-09-04T12:00:53.447324Z","shell.execute_reply.started":"2024-09-04T12:00:53.442148Z"},"trusted":true},"outputs":[],"source":["def load_json_data(dir_name):\n","\n","  data=[]\n","  for root_folder in os.listdir(dir_name):\n","    if root_folder!=\".git\" and root_folder!=\".gitattributes\":\n","      for files in os.listdir(os.path.join(dir_name,root_folder)):\n","        if files.endswith(\".json\"):\n","          with open(os.path.join(dir_name,root_folder,files),\"r\")as f:\n","            json_file=json.load(f)\n","            data.append(json_file)\n","  return data"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:00:54.754853Z","iopub.status.busy":"2024-09-04T12:00:54.754247Z","iopub.status.idle":"2024-09-04T12:00:58.672281Z","shell.execute_reply":"2024-09-04T12:00:58.671266Z","shell.execute_reply.started":"2024-09-04T12:00:54.754814Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading dataset from /dataset/...\n"]}],"source":["print(f\"Loading dataset from ./{dataset_path}/\")\n","json_data=load_json_data(dataset_path)\n","print(f\"Length of loaded dataset is: {len(json_data)}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:01:11.970671Z","iopub.status.busy":"2024-09-04T12:01:11.969805Z","iopub.status.idle":"2024-09-04T12:01:11.975288Z","shell.execute_reply":"2024-09-04T12:01:11.974091Z","shell.execute_reply.started":"2024-09-04T12:01:11.970625Z"},"trusted":true},"outputs":[],"source":["tmp=json_data  # in case if this is required again"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:01:13.631110Z","iopub.status.busy":"2024-09-04T12:01:13.630417Z","iopub.status.idle":"2024-09-04T12:01:13.635824Z","shell.execute_reply":"2024-09-04T12:01:13.634868Z","shell.execute_reply.started":"2024-09-04T12:01:13.631067Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of dataset is: 1000\n"]}],"source":["json_data=json_data[:1000]\n","print(f\"Length of dataset is: {len(json_data)}\")"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:01:15.380660Z","iopub.status.busy":"2024-09-04T12:01:15.380272Z","iopub.status.idle":"2024-09-04T12:01:15.435627Z","shell.execute_reply":"2024-09-04T12:01:15.434751Z","shell.execute_reply.started":"2024-09-04T12:01:15.380622Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading dataset...\n"]}],"source":["print(\"Loading dataset...\")\n","df=Dataset.from_list(json_data)\n","print(df)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:01:16.655522Z","iopub.status.busy":"2024-09-04T12:01:16.654696Z","iopub.status.idle":"2024-09-04T12:01:16.664035Z","shell.execute_reply":"2024-09-04T12:01:16.663103Z","shell.execute_reply.started":"2024-09-04T12:01:16.655473Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['instruction', 'output'],\n","    num_rows: 1000\n","})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:01:23.139201Z","iopub.status.busy":"2024-09-04T12:01:23.138498Z","iopub.status.idle":"2024-09-04T12:01:23.145454Z","shell.execute_reply":"2024-09-04T12:01:23.144467Z","shell.execute_reply.started":"2024-09-04T12:01:23.139161Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'instruction': Value(dtype='string', id=None),\n"," 'output': Value(dtype='string', id=None)}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df.features"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:01:31.139317Z","iopub.status.busy":"2024-09-04T12:01:31.138458Z","iopub.status.idle":"2024-09-04T12:01:31.151413Z","shell.execute_reply":"2024-09-04T12:01:31.150518Z","shell.execute_reply.started":"2024-09-04T12:01:31.139274Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Generate a unit test case for the following Java method: SourceFileResolver { public static File resolveSourceFile( List<String> sourcePaths, String sourceFileName, String groupId, String artifactId ) { return resolveSourceFile( sourceFileName, PathUtil.filesList( sourcePaths ), groupId, artifactId ); }  static File resolveSourceFile( List<String> sourcePaths, String sourceFileName, String groupId,\\n                                          String artifactId ); static File resolveSourceFile( List<String> sourcePaths, String sourceFile ); static File resolveSourceFile( String sourceFileName, List<File> sourceRoots ); static File resolveSourceFile( String sourceFileName, List<File> sourceRoots, String groupId,\\n                                          String artifactId );  }'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["print(df['instruction'][0])"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:01:32.321388Z","iopub.status.busy":"2024-09-04T12:01:32.320758Z","iopub.status.idle":"2024-09-04T12:01:32.329607Z","shell.execute_reply":"2024-09-04T12:01:32.328595Z","shell.execute_reply.started":"2024-09-04T12:01:32.321345Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'The unit test case for the given Java method is: @Test public void resolveMultipleRoots() { File file = SourceFileResolver.resolveSourceFile( null, getDir( \"nroots/root1\", \"nroots/root2\", \"nroots/root3\" ), null, null ); Assert.assertTrue( file.exists() ); MatcherAssert.assertThat( file.getName(), CoreMatchers.equalTo( \"root.as\" ) ); }'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["print(df['output'][0])"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:01:35.720193Z","iopub.status.busy":"2024-09-04T12:01:35.719310Z","iopub.status.idle":"2024-09-04T12:01:35.746045Z","shell.execute_reply":"2024-09-04T12:01:35.744971Z","shell.execute_reply.started":"2024-09-04T12:01:35.720150Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Spliting dataset...\n"]}],"source":["print(\"Spliting dataset...\")\n","df=df.train_test_split(test_size=0.2)\n","print(df)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:01:51.227531Z","iopub.status.busy":"2024-09-04T12:01:51.227127Z","iopub.status.idle":"2024-09-04T12:01:51.232422Z","shell.execute_reply":"2024-09-04T12:01:51.231226Z","shell.execute_reply.started":"2024-09-04T12:01:51.227492Z"},"trusted":true},"outputs":[],"source":["train=df['train']\n","test=df['test']"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:01:52.626322Z","iopub.status.busy":"2024-09-04T12:01:52.625913Z","iopub.status.idle":"2024-09-04T12:01:52.632735Z","shell.execute_reply":"2024-09-04T12:01:52.631814Z","shell.execute_reply.started":"2024-09-04T12:01:52.626284Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['instruction', 'output'],\n","    num_rows: 800\n","})"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["print(train)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:02:01.102333Z","iopub.status.busy":"2024-09-04T12:02:01.101961Z","iopub.status.idle":"2024-09-04T12:02:01.108557Z","shell.execute_reply":"2024-09-04T12:02:01.107529Z","shell.execute_reply.started":"2024-09-04T12:02:01.102299Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['instruction', 'output'],\n","    num_rows: 200\n","})"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["print(test)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:02:02.537217Z","iopub.status.busy":"2024-09-04T12:02:02.536496Z","iopub.status.idle":"2024-09-04T12:02:04.051296Z","shell.execute_reply":"2024-09-04T12:02:04.050310Z","shell.execute_reply.started":"2024-09-04T12:02:02.537178Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading tokenizer...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2059ab6b2c6f4049ae8127d18c98bbef","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.87k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d4eab2096ef4a92ba94447adafcf4cf","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["print(\"Loading tokenizer...\")\n","tokenizer = AutoTokenizer.from_pretrained(base_model)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:02:07.766172Z","iopub.status.busy":"2024-09-04T12:02:07.765799Z","iopub.status.idle":"2024-09-04T12:02:07.784996Z","shell.execute_reply":"2024-09-04T12:02:07.784062Z","shell.execute_reply.started":"2024-09-04T12:02:07.766137Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [32013, 7605, 387, 245, 5621, 1719, 1452, 327, 254, 1884, 9840, 2040, 25, 380, 6327, 508, 7207, 507, 1171, 12353, 7928, 1270, 3314, 1013, 51, 8121, 380, 6327, 508, 29, 323, 3341, 938, 10647, 7, 10647, 270, 8, 8474, 13147, 10647, 508, 3305, 507, 967, 3341, 938, 10647, 7, 65, 13, 24657, 7, 10647, 508, 13, 6787, 57, 650, 270, 477, 611, 207, 1171, 12353, 7928, 3314, 323, 3341, 938, 10647, 7, 10647, 270, 477, 1171, 12353, 7928, 1171, 6159, 1476, 54, 1661, 787, 1195, 309, 19791, 2456, 3314, 323, 3341, 938, 10647, 7, 3667, 27, 51, 29, 495, 82, 11, 380, 6327, 270, 477, 1171, 12353, 7928, 1171, 6159, 1476, 54, 1661, 787, 1195, 309, 19791, 2456, 3314, 323, 3341, 938, 10647, 7, 2005, 1208, 11, 380, 6327, 270, 477, 207, 611], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"]}],"source":["instruction = tokenizer(train['instruction'][0])\n","print(instruction)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:02:11.641864Z","iopub.status.busy":"2024-09-04T12:02:11.641461Z","iopub.status.idle":"2024-09-04T12:02:11.646923Z","shell.execute_reply":"2024-09-04T12:02:11.646011Z","shell.execute_reply.started":"2024-09-04T12:02:11.641827Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['<｜begin▁of▁sentence｜>', 'Gener', 'ate', 'Ġa', 'Ġunit', 'Ġtest', 'Ġcase', 'Ġfor', 'Ġthe', 'Ġfollowing', 'ĠJava', 'Ġmethod', ':', 'ĠB', 'undle', 'able', 'Util', 'Ġ{', 'Ġ@', 'Non', 'Null', 'Ġpublic', 'Ġstatic', 'Ġ<', 'T', 'Ġextends', 'ĠB', 'undle', 'able', '>', 'ĠT', 'Ġmaterial', 'ize', 'Bundle', '(', 'Bundle', 'Ġb', ')', 'Ġthrows', 'ĠBad', 'Bundle', 'able', 'Exception', 'Ġ{', 'Ġreturn', 'Ġmaterial', 'ize', 'Bundle', '(', 'b', '.', 'getString', '(', 'Bundle', 'able', '.', 'CL', 'Z', '),', 'Ġb', ');', 'Ġ}', 'Ġ', 'Ġ@', 'Non', 'Null', 'Ġstatic', 'ĠT', 'Ġmaterial', 'ize', 'Bundle', '(', 'Bundle', 'Ġb', ');', 'Ġ@', 'Non', 'Null', 'Ġ@', 'Sup', 'press', 'W', 'arn', 'ings', '(\"', 'un', 'checked', '\")', 'Ġstatic', 'ĠT', 'Ġmaterial', 'ize', 'Bundle', '(', 'Class', '<', 'T', '>', 'Ġcl', 's', ',', 'ĠB', 'undle', 'Ġb', ');', 'Ġ@', 'Non', 'Null', 'Ġ@', 'Sup', 'press', 'W', 'arn', 'ings', '(\"', 'un', 'checked', '\")', 'Ġstatic', 'ĠT', 'Ġmaterial', 'ize', 'Bundle', '(', 'String', 'Ġname', ',', 'ĠB', 'undle', 'Ġb', ');', 'Ġ', 'Ġ}']\n"]}],"source":["tokens = tokenizer.convert_ids_to_tokens(instruction.input_ids)\n","print(tokens)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:02:16.863996Z","iopub.status.busy":"2024-09-04T12:02:16.863567Z","iopub.status.idle":"2024-09-04T12:02:16.870977Z","shell.execute_reply":"2024-09-04T12:02:16.870056Z","shell.execute_reply.started":"2024-09-04T12:02:16.863955Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'<｜begin▁of▁sentence｜>Generate a unit test case for the following Java method: BundleableUtil { @NonNull public static <T extends Bundleable> T materializeBundle(Bundle b) throws BadBundleableException { return materializeBundle(b.getString(Bundleable.CLZ), b); }  @NonNull static T materializeBundle(Bundle b); @NonNull @SuppressWarnings(\"unchecked\") static T materializeBundle(Class<T> cls, Bundle b); @NonNull @SuppressWarnings(\"unchecked\") static T materializeBundle(String name, Bundle b);  }'"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.convert_tokens_to_string(tokens)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:02:23.606097Z","iopub.status.busy":"2024-09-04T12:02:23.605406Z","iopub.status.idle":"2024-09-04T12:02:23.610749Z","shell.execute_reply":"2024-09-04T12:02:23.609790Z","shell.execute_reply.started":"2024-09-04T12:02:23.606057Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocab size : 32000\n"]}],"source":["print(f\"Vocab size : {tokenizer.vocab_size}\")\n","print(f\"max length : {tokenizer.model_max_length}\")\n","print(f\"model input : {tokenizer.model_input_names}\")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:02:41.220694Z","iopub.status.busy":"2024-09-04T12:02:41.219735Z","iopub.status.idle":"2024-09-04T12:02:41.236339Z","shell.execute_reply":"2024-09-04T12:02:41.235360Z","shell.execute_reply.started":"2024-09-04T12:02:41.220636Z"},"trusted":true},"outputs":[],"source":["batch = tokenizer(train['instruction'][0],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n","print(batch)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:03:04.369372Z","iopub.status.busy":"2024-09-04T12:03:04.368498Z","iopub.status.idle":"2024-09-04T12:03:05.997740Z","shell.execute_reply":"2024-09-04T12:03:05.996735Z","shell.execute_reply.started":"2024-09-04T12:03:04.369329Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['instruction', 'output'],\n","    num_rows: 78534\n","})"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# tmp=Dataset.from_list(tmp)\n","# tmp"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:03:09.501378Z","iopub.status.busy":"2024-09-04T12:03:09.500761Z","iopub.status.idle":"2024-09-04T12:03:09.506707Z","shell.execute_reply":"2024-09-04T12:03:09.505775Z","shell.execute_reply.started":"2024-09-04T12:03:09.501335Z"},"trusted":true},"outputs":[],"source":["# # Define the build_instruction_prompt function\n","# def build_instruction_prompt(instruction: str):\n","#     return '''\n","# You are an AI programming assistant, utilizing the DeepSeek Coder model, developed by DeepSeek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n","# ### Instruction:\n","# {}\n","# ### Response:\n","# '''.format(instruction.strip()).lstrip()\n","\n","# # Define the EOT_TOKEN\n","# EOT_TOKEN = \"<|EOT|>\""]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:03:11.611460Z","iopub.status.busy":"2024-09-04T12:03:11.611071Z","iopub.status.idle":"2024-09-04T12:03:11.617408Z","shell.execute_reply":"2024-09-04T12:03:11.616372Z","shell.execute_reply.started":"2024-09-04T12:03:11.611422Z"},"trusted":true},"outputs":[],"source":["def tokenize_data(data):\n","  input_col=tokenizer(data['instruction'],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n","  target_col=tokenizer(data['output'],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n","\n","  return {\n","      \"input_ids\":input_col[\"input_ids\"],\n","      \"attention_mask\":input_col[\"attention_mask\"],\n","      \"labels\":target_col[\"input_ids\"]\n","  }"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T13:24:06.354976Z","iopub.status.busy":"2024-09-04T13:24:06.354020Z","iopub.status.idle":"2024-09-04T13:24:06.360078Z","shell.execute_reply":"2024-09-04T13:24:06.359137Z","shell.execute_reply.started":"2024-09-04T13:24:06.354935Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Tokenizing dataset...\n"]}],"source":["tokenizer.padding_side = \"right\"\n","print(\"Tokenizing dataset...\")"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:03:23.606127Z","iopub.status.busy":"2024-09-04T12:03:23.605417Z","iopub.status.idle":"2024-09-04T12:03:25.453805Z","shell.execute_reply":"2024-09-04T12:03:25.452895Z","shell.execute_reply.started":"2024-09-04T12:03:23.606069Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mapping train data...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"54fe29881c9549919602139ae354c6c0","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/800 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["print(\"Mapping train data...\")\n","train=train.map(tokenize_data,batched=True)\n","print(train)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:03:39.246107Z","iopub.status.busy":"2024-09-04T12:03:39.245697Z","iopub.status.idle":"2024-09-04T12:03:39.807467Z","shell.execute_reply":"2024-09-04T12:03:39.806496Z","shell.execute_reply.started":"2024-09-04T12:03:39.246067Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mappig test data...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2515390298cc432faa2e3618a430c8ed","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/200 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["print(\"Mappig test data...\")\n","test=test.map(tokenize_data,batched=True)\n","print(test)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:03:44.906794Z","iopub.status.busy":"2024-09-04T12:03:44.906376Z","iopub.status.idle":"2024-09-04T12:03:44.915475Z","shell.execute_reply":"2024-09-04T12:03:44.914660Z","shell.execute_reply.started":"2024-09-04T12:03:44.906753Z"},"trusted":true},"outputs":[],"source":["train=train.remove_columns([\"instruction\",\"output\"])\n","test=test.remove_columns([\"instruction\",\"output\"])"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:03:45.828804Z","iopub.status.busy":"2024-09-04T12:03:45.828194Z","iopub.status.idle":"2024-09-04T12:03:45.834616Z","shell.execute_reply":"2024-09-04T12:03:45.833650Z","shell.execute_reply.started":"2024-09-04T12:03:45.828763Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 800\n","})"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["print(train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def print_number_of_trainable_model_parameters(model):\n","    trainable_model_params = 0\n","    all_model_params = 0\n","    for _, param in model.named_parameters():\n","        all_model_params += param.numel()\n","        if param.requires_grad:\n","            trainable_model_params += param.numel()\n","    return f'trainable model parameters: {trainable_model_params}\\n \\\n","            all model parameters: {all_model_params} \\n \\\n","            percentage of trainable model parameters: {(trainable_model_params / all_model_params) * 100} %'"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:03:46.750119Z","iopub.status.busy":"2024-09-04T12:03:46.749371Z","iopub.status.idle":"2024-09-04T12:03:46.811231Z","shell.execute_reply":"2024-09-04T12:03:46.810285Z","shell.execute_reply.started":"2024-09-04T12:03:46.750074Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA device: Tesla P100-PCIE-16GB\n"]}],"source":["if torch.cuda.is_available():\n","    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n","    device={\"\":0}\n","    torch_type=torch.bfloat16\n","else:\n","    device=\"cpu\"\n","    torch_type=torch.bfloat16\n","    print(\"I am begging for mercy already!\")"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:19:19.156444Z","iopub.status.busy":"2024-09-04T12:19:19.156057Z","iopub.status.idle":"2024-09-04T12:19:23.460634Z","shell.execute_reply":"2024-09-04T12:19:23.459633Z","shell.execute_reply.started":"2024-09-04T12:19:19.156411Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--deepseek-ai--deepseek-coder-1.3b-instruct/snapshots/e063262dac8366fc1f28a4da0ff3c50ea66259ca/config.json\n","Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n","Model config LlamaConfig {\n","  \"_name_or_path\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 32013,\n","  \"eos_token_id\": 32021,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 5504,\n","  \"max_position_embeddings\": 16384,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 16,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": {\n","    \"factor\": 4.0,\n","    \"rope_type\": \"linear\",\n","    \"type\": \"linear\"\n","  },\n","  \"rope_theta\": 100000,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32256\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--deepseek-ai--deepseek-coder-1.3b-instruct/snapshots/e063262dac8366fc1f28a4da0ff3c50ea66259ca/model.safetensors\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 32013,\n","  \"eos_token_id\": 32021\n","}\n","\n","All model checkpoint weights were used when initializing LlamaForCausalLM.\n","\n","All the weights of LlamaForCausalLM were initialized from the model checkpoint at deepseek-ai/deepseek-coder-1.3b-instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n","loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--deepseek-ai--deepseek-coder-1.3b-instruct/snapshots/e063262dac8366fc1f28a4da0ff3c50ea66259ca/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 32013,\n","  \"eos_token_id\": 32021\n","}\n","\n"]}],"source":["model = AutoModelForCausalLM.from_pretrained(base_model,device_map=device)"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:19:33.489981Z","iopub.status.busy":"2024-09-04T12:19:33.489590Z","iopub.status.idle":"2024-09-04T12:19:33.497292Z","shell.execute_reply":"2024-09-04T12:19:33.496375Z","shell.execute_reply.started":"2024-09-04T12:19:33.489940Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(32256, 2048)\n","    (layers): ModuleList(\n","      (0-23): 24 x LlamaDecoderLayer(\n","        (self_attn): LlamaSdpaAttention(\n","          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n","          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n","          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n","          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)\n","          (up_proj): Linear(in_features=2048, out_features=5504, bias=False)\n","          (down_proj): Linear(in_features=5504, out_features=2048, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n","        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n","      )\n","    )\n","    (norm): LlamaRMSNorm((2048,), eps=1e-06)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=2048, out_features=32256, bias=False)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:19:42.297838Z","iopub.status.busy":"2024-09-04T12:19:42.297205Z","iopub.status.idle":"2024-09-04T12:19:42.304528Z","shell.execute_reply":"2024-09-04T12:19:42.303629Z","shell.execute_reply.started":"2024-09-04T12:19:42.297799Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable model parameters: 1346471936\n","             all model parameters: 1346471936 \n","             percentage of trainable model parameters: 100.0 %\n"]}],"source":["print(print_number_of_trainable_model_parameters(model))"]},{"cell_type":"markdown","metadata":{},"source":["**Nested quantization**\n","For enabling nested quantization, use the bnb_4bit_use_double_quant argument in BitsAndBytesConfig. This will enable a second quantization after the first one to save an additional 0.4 bits per parameter."]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:19:52.525633Z","iopub.status.busy":"2024-09-04T12:19:52.525182Z","iopub.status.idle":"2024-09-04T12:19:55.819292Z","shell.execute_reply":"2024-09-04T12:19:55.818490Z","shell.execute_reply.started":"2024-09-04T12:19:52.525590Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--deepseek-ai--deepseek-coder-1.3b-instruct/snapshots/e063262dac8366fc1f28a4da0ff3c50ea66259ca/config.json\n","Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n","Model config LlamaConfig {\n","  \"_name_or_path\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 32013,\n","  \"eos_token_id\": 32021,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 5504,\n","  \"max_position_embeddings\": 16384,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 16,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": {\n","    \"factor\": 4.0,\n","    \"rope_type\": \"linear\",\n","    \"type\": \"linear\"\n","  },\n","  \"rope_theta\": 100000,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32256\n","}\n","\n","Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\n","The device_map was not initialized. Setting device_map to {'':torch.cuda.current_device()}. If you want to use the model for inference, please set device_map ='auto' \n","`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--deepseek-ai--deepseek-coder-1.3b-instruct/snapshots/e063262dac8366fc1f28a4da0ff3c50ea66259ca/model.safetensors\n","Instantiating LlamaForCausalLM model under default dtype torch.float16.\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 32013,\n","  \"eos_token_id\": 32021\n","}\n","\n","All model checkpoint weights were used when initializing LlamaForCausalLM.\n","\n","All the weights of LlamaForCausalLM were initialized from the model checkpoint at deepseek-ai/deepseek-coder-1.3b-instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n","loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--deepseek-ai--deepseek-coder-1.3b-instruct/snapshots/e063262dac8366fc1f28a4da0ff3c50ea66259ca/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 32013,\n","  \"eos_token_id\": 32021\n","}\n","\n"]}],"source":["nf4_config = BitsAndBytesConfig(\n","   load_in_4bit=True,\n","   bnb_4bit_quant_type=\"nf4\",\n","   bnb_4bit_use_double_quant=True,\n","   bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","model_nf4 = AutoModelForCausalLM.from_pretrained(base_model, quantization_config=nf4_config)"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:20:29.107492Z","iopub.status.busy":"2024-09-04T12:20:29.107073Z","iopub.status.idle":"2024-09-04T12:20:29.115312Z","shell.execute_reply":"2024-09-04T12:20:29.114241Z","shell.execute_reply.started":"2024-09-04T12:20:29.107452Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(32256, 2048)\n","    (layers): ModuleList(\n","      (0-23): 24 x LlamaDecoderLayer(\n","        (self_attn): LlamaSdpaAttention(\n","          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n","          (k_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n","          (v_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n","          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): Linear4bit(in_features=2048, out_features=5504, bias=False)\n","          (up_proj): Linear4bit(in_features=2048, out_features=5504, bias=False)\n","          (down_proj): Linear4bit(in_features=5504, out_features=2048, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n","        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-06)\n","      )\n","    )\n","    (norm): LlamaRMSNorm((2048,), eps=1e-06)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=2048, out_features=32256, bias=False)\n",")\n"]}],"source":["print(model_nf4)"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:20:55.682335Z","iopub.status.busy":"2024-09-04T12:20:55.681927Z","iopub.status.idle":"2024-09-04T12:20:55.689179Z","shell.execute_reply":"2024-09-04T12:20:55.688162Z","shell.execute_reply.started":"2024-09-04T12:20:55.682295Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable model parameters: 132220928\n","             all model parameters: 739346432 \n","             percentage of trainable model parameters: 17.883487669282484 %\n"]}],"source":["print(print_number_of_trainable_model_parameters(model_nf4))"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:04:42.959795Z","iopub.status.busy":"2024-09-04T12:04:42.958932Z","iopub.status.idle":"2024-09-04T12:04:42.964322Z","shell.execute_reply":"2024-09-04T12:04:42.963314Z","shell.execute_reply.started":"2024-09-04T12:04:42.959756Z"},"trusted":true},"outputs":[],"source":["lora_config = LoraConfig(\n","    r=64,\n","    lora_alpha=16,\n","    lora_dropout = 0.1,\n","    bias='none',\n","    task_type=\"CAUSAL_LM\"\n",")"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:23:02.944106Z","iopub.status.busy":"2024-09-04T12:23:02.943693Z","iopub.status.idle":"2024-09-04T12:23:03.094171Z","shell.execute_reply":"2024-09-04T12:23:03.093257Z","shell.execute_reply.started":"2024-09-04T12:23:02.944068Z"},"trusted":true},"outputs":[],"source":["peft_model = get_peft_model(model_nf4, lora_config)\n","print(peft_model)"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:23:12.249134Z","iopub.status.busy":"2024-09-04T12:23:12.248127Z","iopub.status.idle":"2024-09-04T12:23:12.257437Z","shell.execute_reply":"2024-09-04T12:23:12.256415Z","shell.execute_reply.started":"2024-09-04T12:23:12.249093Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable model parameters: 6291456\n","             all model parameters: 745637888 \n","             percentage of trainable model parameters: 0.8437682823327776 %\n"]}],"source":["print(print_number_of_trainable_model_parameters(peft_model))"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T12:05:32.417123Z","iopub.status.busy":"2024-09-04T12:05:32.416377Z","iopub.status.idle":"2024-09-04T12:05:32.423637Z","shell.execute_reply":"2024-09-04T12:05:32.422614Z","shell.execute_reply.started":"2024-09-04T12:05:32.417060Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BF16 support is True\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:455: FutureWarning: The util is_torch_bf16_available is deprecated, please use is_torch_bf16_gpu_available or is_torch_bf16_cpu_available instead according to whether it's used with cpu or gpu\n","  warnings.warn(\n"]}],"source":["print(f\"BF16 support is {transformers.utils.import_utils.is_torch_bf16_gpu_available()}\")"]},{"cell_type":"code","execution_count":91,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T13:26:39.506733Z","iopub.status.busy":"2024-09-04T13:26:39.505719Z","iopub.status.idle":"2024-09-04T13:26:39.538682Z","shell.execute_reply":"2024-09-04T13:26:39.537853Z","shell.execute_reply.started":"2024-09-04T13:26:39.506688Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n"]}],"source":["training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    run_name =\"./loggings\",\n","    overwrite_output_dir=True,\n","    eval_strategy=\"steps\",\n","    learning_rate=5e-5, # default, change to 1e-3 on epoch>4\n","    gradient_accumulation_steps=1, # if CUDA out of memory then = 3,4\n","#     per_device_train_batch_size=8,\n","#     per_device_eval_batch_size=8,\n","    auto_find_batch_size = True, # for CUDA out of memory \n","    weight_decay=0.01,\n","    num_train_epochs=1, # test=1, min=4, max=10\n","    bf16=True,\n","    optim=\"adamw_torch\",\n","    save_strategy=\"no\",\n","    log_level=\"info\",\n","    logging_first_step=True,\n","    report_to='none' ## can be wandb, but we dont need right now!\n",")"]},{"cell_type":"code","execution_count":93,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T13:26:55.945261Z","iopub.status.busy":"2024-09-04T13:26:55.944401Z","iopub.status.idle":"2024-09-04T13:26:56.171604Z","shell.execute_reply":"2024-09-04T13:26:56.170646Z","shell.execute_reply.started":"2024-09-04T13:26:55.945215Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","Using auto half precision backend\n"]}],"source":["trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=train,\n","    eval_dataset=test,\n","    # peft_config=lora_config,\n","    dataset_text_field=\"text\",\n","    # max_seq_length=None,\n","    tokenizer=tokenizer,\n","    args=training_args,\n","    packing=False,\n",")"]},{"cell_type":"code","execution_count":94,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T13:27:10.030628Z","iopub.status.busy":"2024-09-04T13:27:10.030217Z","iopub.status.idle":"2024-09-04T13:35:39.839903Z","shell.execute_reply":"2024-09-04T13:35:39.838971Z","shell.execute_reply.started":"2024-09-04T13:27:10.030588Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 800\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 100\n","  Number of trainable parameters = 6,291,456\n","***** Running training *****\n","  Num examples = 800\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Training with DataParallel so batch size has been adjusted to: 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 200\n","  Number of trainable parameters = 6,291,456\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 08:22, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.292400</td>\n","      <td>1.043586</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\n","***** Running Evaluation *****\n","  Num examples = 200\n","  Batch size = 8\n","We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=200, training_loss=1.21825543820858, metrics={'train_runtime': 504.8575, 'train_samples_per_second': 1.585, 'train_steps_per_second': 0.396, 'total_flos': 3162201548390400.0, 'train_loss': 1.21825543820858, 'epoch': 1.0})"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T13:35:49.403213Z","iopub.status.busy":"2024-09-04T13:35:49.402768Z","iopub.status.idle":"2024-09-04T13:35:49.786649Z","shell.execute_reply":"2024-09-04T13:35:49.785651Z","shell.execute_reply.started":"2024-09-04T13:35:49.403174Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--deepseek-ai--deepseek-coder-1.3b-instruct/snapshots/e063262dac8366fc1f28a4da0ff3c50ea66259ca/config.json\n","Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n","Model config LlamaConfig {\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 32013,\n","  \"eos_token_id\": 32021,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 5504,\n","  \"max_position_embeddings\": 16384,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 16,\n","  \"pretraining_tp\": 1,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_scaling\": {\n","    \"factor\": 4.0,\n","    \"rope_type\": \"linear\",\n","    \"type\": \"linear\"\n","  },\n","  \"rope_theta\": 100000,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32256\n","}\n","\n","tokenizer config file saved in CODEX-deepseek-coder-1.3b-instruct/tokenizer_config.json\n","Special tokens file saved in CODEX-deepseek-coder-1.3b-instruct/special_tokens_map.json\n"]},{"data":{"text/plain":["('CODEX-deepseek-coder-1.3b-instruct/tokenizer_config.json',\n"," 'CODEX-deepseek-coder-1.3b-instruct/special_tokens_map.json',\n"," 'CODEX-deepseek-coder-1.3b-instruct/tokenizer.json')"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":["trainer.model.save_pretrained(new_model)\n","trainer.tokenizer.save_pretrained(new_model)"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T13:36:11.045771Z","iopub.status.busy":"2024-09-04T13:36:11.045340Z","iopub.status.idle":"2024-09-04T13:36:11.355759Z","shell.execute_reply":"2024-09-04T13:36:11.354641Z","shell.execute_reply.started":"2024-09-04T13:36:11.045716Z"},"trusted":true},"outputs":[],"source":["# torch.cuda.empty_cache()  # release CUDA memory"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":4}
