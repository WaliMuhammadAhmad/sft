{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture \n%pip install -U accelerate peft bitsandbytes transformers trl evaluate attrdict tqdm datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-05T13:10:47.534971Z","iopub.execute_input":"2024-09-05T13:10:47.535283Z","iopub.status.idle":"2024-09-05T13:11:21.391634Z","shell.execute_reply.started":"2024-09-05T13:10:47.535249Z","shell.execute_reply":"2024-09-05T13:11:21.390390Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport json\nimport shutil\nimport logging\nimport transformers\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    get_peft_model,\n    TaskType,\n    PeftModel, \n    PeftConfig\n)\nfrom evaluate import load\nfrom trl import SFTTrainer\nfrom datasets import Dataset, load_dataset\nfrom huggingface_hub import login, Repository","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:11:21.393569Z","iopub.execute_input":"2024-09-05T13:11:21.393913Z","iopub.status.idle":"2024-09-05T13:11:41.438191Z","shell.execute_reply.started":"2024-09-05T13:11:21.393878Z","shell.execute_reply":"2024-09-05T13:11:41.437394Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model = \"deepseek-coder-6.7b-instruct\"  # model to be fine-tuned\n\nbase_model = \"deepseek-ai/deepseek-coder-6.7b-instruct\"  # actual model name\n\nnew_model = \"CODEX-deepseek-coder-6.7b-instruct\"  # fine-tunned model name\n\ndataset_path = \"dataset\"  # dataset dir path\n\ndataset = \"CodexAI/Deepseek-Coder\"  # dataset name at huggingface\n\nrepo_url = f'https://huggingface.co/datasets/{dataset}'","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:38.987811Z","iopub.execute_input":"2024-09-05T13:13:38.988917Z","iopub.status.idle":"2024-09-05T13:13:38.993631Z","shell.execute_reply.started":"2024-09-05T13:13:38.988880Z","shell.execute_reply":"2024-09-05T13:13:38.992731Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nlogin(UserSecretsClient().get_secret(\"HF_TOKEN\"))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:39.838588Z","iopub.execute_input":"2024-09-05T13:13:39.839422Z","iopub.status.idle":"2024-09-05T13:13:40.188049Z","shell.execute_reply.started":"2024-09-05T13:13:39.839381Z","shell.execute_reply":"2024-09-05T13:13:40.187167Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"# if not os.path.exists(dataset_path):\n#     os.makedirs(dataset_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:41.688760Z","iopub.execute_input":"2024-09-05T13:13:41.689352Z","iopub.status.idle":"2024-09-05T13:13:41.693216Z","shell.execute_reply.started":"2024-09-05T13:13:41.689317Z","shell.execute_reply":"2024-09-05T13:13:41.692209Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# repo = Repository(local_dir=dataset_path,clone_from=repo_url)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:42.064067Z","iopub.execute_input":"2024-09-05T13:13:42.064432Z","iopub.status.idle":"2024-09-05T13:13:42.068441Z","shell.execute_reply.started":"2024-09-05T13:13:42.064396Z","shell.execute_reply":"2024-09-05T13:13:42.067427Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def load_json_data(dir_name):\n\n  data=[]\n  for root_folder in os.listdir(dir_name):\n    if root_folder!=\".git\" and root_folder!=\".gitattributes\":\n      for files in os.listdir(os.path.join(dir_name,root_folder)):\n        if files.endswith(\".json\"):\n          with open(os.path.join(dir_name,root_folder,files),\"r\")as f:\n            json_file=json.load(f)\n            data.append(json_file)\n  return data","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:42.475616Z","iopub.execute_input":"2024-09-05T13:13:42.475991Z","iopub.status.idle":"2024-09-05T13:13:42.482203Z","shell.execute_reply.started":"2024-09-05T13:13:42.475958Z","shell.execute_reply":"2024-09-05T13:13:42.481263Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(f\"Loading dataset from ./{dataset_path}/...\")\njson_data=load_json_data(dataset_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:42.785082Z","iopub.execute_input":"2024-09-05T13:13:42.786086Z","iopub.status.idle":"2024-09-05T13:13:46.743799Z","shell.execute_reply.started":"2024-09-05T13:13:42.786045Z","shell.execute_reply":"2024-09-05T13:13:46.742967Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Loading dataset from ./dataset/...\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Length of loaded dataset is: {len(json_data)}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:46.745302Z","iopub.execute_input":"2024-09-05T13:13:46.745609Z","iopub.status.idle":"2024-09-05T13:13:46.750667Z","shell.execute_reply.started":"2024-09-05T13:13:46.745577Z","shell.execute_reply":"2024-09-05T13:13:46.749757Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Length of loaded dataset is: 78534\n","output_type":"stream"}]},{"cell_type":"code","source":"tmp=json_data  # in case if this is required again","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:46.751819Z","iopub.execute_input":"2024-09-05T13:13:46.752113Z","iopub.status.idle":"2024-09-05T13:13:46.763569Z","shell.execute_reply.started":"2024-09-05T13:13:46.752065Z","shell.execute_reply":"2024-09-05T13:13:46.762715Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"json_data=json_data[:1000]\nprint(f\"Length of dataset is: {len(json_data)}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:46.765471Z","iopub.execute_input":"2024-09-05T13:13:46.765780Z","iopub.status.idle":"2024-09-05T13:13:46.774558Z","shell.execute_reply.started":"2024-09-05T13:13:46.765750Z","shell.execute_reply":"2024-09-05T13:13:46.773736Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Length of dataset is: 1000\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Loading dataset...\")\ndf=Dataset.from_list(json_data)\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:46.775511Z","iopub.execute_input":"2024-09-05T13:13:46.775785Z","iopub.status.idle":"2024-09-05T13:13:46.823587Z","shell.execute_reply.started":"2024-09-05T13:13:46.775755Z","shell.execute_reply":"2024-09-05T13:13:46.822739Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Loading dataset...\nDataset({\n    features: ['instruction', 'output'],\n    num_rows: 1000\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"df.features","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:46.824534Z","iopub.execute_input":"2024-09-05T13:13:46.824818Z","iopub.status.idle":"2024-09-05T13:13:46.831660Z","shell.execute_reply.started":"2024-09-05T13:13:46.824788Z","shell.execute_reply":"2024-09-05T13:13:46.830774Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'instruction': Value(dtype='string', id=None),\n 'output': Value(dtype='string', id=None)}"},"metadata":{}}]},{"cell_type":"code","source":"print(df['instruction'][0])","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:46.832679Z","iopub.execute_input":"2024-09-05T13:13:46.832986Z","iopub.status.idle":"2024-09-05T13:13:46.846653Z","shell.execute_reply.started":"2024-09-05T13:13:46.832956Z","shell.execute_reply":"2024-09-05T13:13:46.845728Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Generate a unit test case for the following Java method: PercentageAnnotator implements SugiliteTextAnnotator { @Override public List<AnnotatingResult> annotate(String text) { text = text.replaceAll(\"[\\\\u00A0\\\\u2007\\\\u202F]+\", \" \"); if (cache.containsKey(text)){ return cache.get(text); } List<AnnotatingResult> results = new ArrayList<>(); String regex = \"\\\\b\\\\d+?(.\\\\d+?)?(\\\\s)?(%|percent)\"; Pattern pattern = Pattern.compile(regex); Matcher matcher = pattern.matcher(text); while (matcher.find()) { try { String matchedString = text.substring(matcher.start(), matcher.end()); if (matcher.start() > 0 && text.charAt(matcher.start() - 1) == '-') matchedString = text.substring(matcher.start() - 1, matcher.end()); String[] parsed = matchedString.split(\"[p %]\"); results.add(new AnnotatingResult(RELATION, text.substring(matcher.start(), matcher.end()), matcher.start(), matcher.end(), Double.valueOf(parsed[0]))); } catch (Exception e) { e.printStackTrace(); } } cache.put(text, results); return results; } PercentageAnnotator(); @Override List<AnnotatingResult> annotate(String text);  }\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df['output'][0])","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:46.847850Z","iopub.execute_input":"2024-09-05T13:13:46.848127Z","iopub.status.idle":"2024-09-05T13:13:46.860767Z","shell.execute_reply.started":"2024-09-05T13:13:46.848097Z","shell.execute_reply":"2024-09-05T13:13:46.859824Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"The unit test case for the given Java method is: @Test public void testMultipleWithBadInput() { List<SugiliteTextParentAnnotator.AnnotatingResult> res = annotator.annotate(\"stock market growth rate:\" + \"-550.1 %, 4, 3.% and 0.0006 percent\"); assertEquals(res.size(), 2); res.sort(Comparator.comparingDouble(SugiliteTextParentAnnotator.AnnotatingResult::getNumericValue)); assertEquals(res.get(0).getNumericValue().intValue(), -550); assertEquals(res.get(1).getNumericValue().intValue(), 0); }\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Spliting dataset...\")\ndf=df.train_test_split(test_size=0.2)\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:46.861861Z","iopub.execute_input":"2024-09-05T13:13:46.862137Z","iopub.status.idle":"2024-09-05T13:13:46.889646Z","shell.execute_reply.started":"2024-09-05T13:13:46.862107Z","shell.execute_reply":"2024-09-05T13:13:46.888825Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Spliting dataset...\nDatasetDict({\n    train: Dataset({\n        features: ['instruction', 'output'],\n        num_rows: 800\n    })\n    test: Dataset({\n        features: ['instruction', 'output'],\n        num_rows: 200\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"train=df['train']\ntest=df['test']","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:46.892821Z","iopub.execute_input":"2024-09-05T13:13:46.893088Z","iopub.status.idle":"2024-09-05T13:13:46.897573Z","shell.execute_reply.started":"2024-09-05T13:13:46.893059Z","shell.execute_reply":"2024-09-05T13:13:46.896733Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(train)\nprint(test)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:46.898782Z","iopub.execute_input":"2024-09-05T13:13:46.899090Z","iopub.status.idle":"2024-09-05T13:13:46.909366Z","shell.execute_reply.started":"2024-09-05T13:13:46.899059Z","shell.execute_reply":"2024-09-05T13:13:46.908653Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['instruction', 'output'],\n    num_rows: 800\n})\nDataset({\n    features: ['instruction', 'output'],\n    num_rows: 200\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Loading tokenizer...\")\ntokenizer = AutoTokenizer.from_pretrained(base_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:46.910296Z","iopub.execute_input":"2024-09-05T13:13:46.910567Z","iopub.status.idle":"2024-09-05T13:13:48.384707Z","shell.execute_reply.started":"2024-09-05T13:13:46.910537Z","shell.execute_reply":"2024-09-05T13:13:48.383902Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Loading tokenizer...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.87k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0725f05eadde4e25b685f5a6215e7964"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e39fe10a601546768b80328b44e4864d"}},"metadata":{}}]},{"cell_type":"code","source":"instruction = tokenizer(train['instruction'][0])\nprint(instruction)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:48.385788Z","iopub.execute_input":"2024-09-05T13:13:48.386075Z","iopub.status.idle":"2024-09-05T13:13:48.405344Z","shell.execute_reply.started":"2024-09-05T13:13:48.386045Z","shell.execute_reply":"2024-09-05T13:13:48.404492Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"{'input_ids': [32013, 7605, 387, 245, 5621, 1719, 1452, 327, 254, 1884, 9840, 2040, 25, 10481, 2714, 7746, 6474, 507, 3314, 2494, 1193, 1597, 54, 11943, 14667, 7, 25924, 22116, 11, 7050, 2816, 16262, 2189, 8474, 20685, 507, 562, 7, 2816, 16262, 2312, 2352, 2189, 967, 26, 6977, 1964, 22301, 405, 6977, 1964, 13, 703, 18451, 7, 10481, 2714, 7746, 6474, 13, 2176, 13, 19796, 3705, 4450, 27, 2005, 29, 8729, 405, 22116, 13, 2600, 6353, 10269, 1293, 327, 7, 2319, 3270, 2119, 1191, 8729, 2189, 507, 562, 7, 2069, 2119, 13, 4779, 82, 3209, 7, 16170, 11087, 62, 12929, 62, 25563, 4208, 62, 11787, 30383, 207, 1435, 4873, 26, 3270, 27492, 3882, 7261, 405, 22116, 13, 703, 6353, 7, 2119, 4363, 3270, 1582, 3790, 405, 2119, 13, 1580, 2600, 7, 16170, 11087, 62, 12929, 62, 25563, 4208, 62, 11787, 30383, 13, 4082, 3705, 562, 7, 27492, 3882, 7261, 2312, 2352, 2189, 507, 22301, 13, 69, 480, 7, 440, 3221, 1753, 3082, 438, 4274, 327, 440, 945, 1582, 3790, 945, 19736, 7030, 12510, 359, 12058, 4363, 4873, 26, 611, 12477, 4807, 1753, 7261, 405, 1450, 734, 4034, 7190, 21, 19, 7, 27492, 3882, 7261, 4363, 3270, 3393, 3882, 405, 22116, 13, 703, 6353, 7, 1582, 3790, 4363, 562, 7, 3393, 3882, 2312, 2352, 2189, 507, 22301, 13, 69, 480, 7, 440, 3221, 3574, 7046, 440, 945, 1582, 3790, 945, 440, 438, 1496, 13, 7030, 12510, 359, 12058, 4363, 4873, 26, 611, 22856, 82, 13, 4981, 16262, 7, 2816, 16262, 4363, 7050, 2816, 405, 756, 7050, 7, 2816, 16262, 11, 756, 7050, 7, 3393, 3882, 16851, 19796, 3705, 22856, 82, 13, 11792, 6620, 7, 756, 31178, 5055, 24734, 7, 1753, 7261, 12651, 2816, 4363, 22301, 13, 4647, 250, 7, 440, 54, 11943, 440, 945, 2119, 945, 440, 473, 2664, 1189, 279, 440, 945, 2816, 13, 703, 22169, 20748, 4693, 3705, 22116, 13, 8680, 7, 2119, 4363, 22116, 13, 1113, 6353, 7, 1582, 3790, 11, 2816, 13, 703, 22169, 20748, 4693, 3705, 611, 611, 2740, 207, 10481, 2714, 7746, 6474, 1293, 3314, 3270, 3697, 5719, 2714, 2111, 2005, 7, 185, 459, 184, 4581, 27, 2005, 11, 2005, 29, 5659, 4243, 11312, 11, 185, 459, 28637, 6980, 11, 185, 459, 28637, 3708, 1737, 11, 185, 459, 28637, 752, 13683, 7552, 4693, 4363, 3314, 25924, 3697, 5719, 2714, 2111, 12461, 7, 185, 459, 184, 4581, 27, 2005, 11, 2005, 29, 5659, 4243, 11312, 11, 185, 459, 28637, 6980, 11, 185, 459, 28637, 3708, 1737, 11, 185, 459, 28637, 752, 13683, 7552, 4693, 4363, 3314, 25924, 1272, 5719, 2714, 7, 3270, 11681, 12461, 11, 7050, 2816, 16262, 4363, 3314, 25924, 1694, 5719, 2714, 7, 25924, 5289, 11, 7050, 2816, 16262, 4363, 3314, 2319, 3270, 324, 3008, 47, 2289, 62, 24607, 18711, 62, 14348, 26, 3314, 2319, 3270, 10538, 8124, 25709, 62, 8648, 26, 3314, 2319, 3270, 23152, 28500, 26, 3314, 2319, 3270, 16170, 11087, 62, 12929, 62, 25563, 4208, 62, 11787, 30383, 26, 611], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","output_type":"stream"}]},{"cell_type":"code","source":"tokens = tokenizer.convert_ids_to_tokens(instruction.input_ids)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:48.406338Z","iopub.execute_input":"2024-09-05T13:13:48.406603Z","iopub.status.idle":"2024-09-05T13:13:48.411582Z","shell.execute_reply.started":"2024-09-05T13:13:48.406573Z","shell.execute_reply":"2024-09-05T13:13:48.410635Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"['<｜begin▁of▁sentence｜>', 'Gener', 'ate', 'Ġa', 'Ġunit', 'Ġtest', 'Ġcase', 'Ġfor', 'Ġthe', 'Ġfollowing', 'ĠJava', 'Ġmethod', ':', 'ĠUser', 'Data', 'Hel', 'pers', 'Ġ{', 'Ġstatic', 'Ġvoid', 'Ġinter', 'cept', 'W', 'riting', 'Files', '(', 'ĠProperties', 'Ġprops', ',', 'ĠFile', 'Ġoutput', 'Directory', 'Ġ)', 'Ġthrows', 'ĠIOException', 'Ġ{', 'Ġif', '(', 'Ġoutput', 'Directory', 'Ġ==', 'Ġnull', 'Ġ)', 'Ġreturn', ';', 'ĠLog', 'ger', 'Ġlogger', 'Ġ=', 'ĠLog', 'ger', '.', 'get', 'Logger', '(', 'ĠUser', 'Data', 'Hel', 'pers', '.', 'class', '.', 'getName', '());', 'ĠSet', '<', 'String', '>', 'Ġkeys', 'Ġ=', 'Ġprops', '.', 'string', 'Property', 'Names', '();', 'Ġfor', '(', 'Ġfinal', 'ĠString', 'Ġkey', 'Ġ:', 'Ġkeys', 'Ġ)', 'Ġ{', 'Ġif', '(', 'Ġ!', 'Ġkey', '.', 'start', 's', 'With', '(', 'ĠEN', 'CODE', '_', 'FILE', '_', 'CONT', 'ENT', '_', 'PRE', 'FIX', 'Ġ', '))', 'Ġcontinue', ';', 'ĠString', 'Ġencoded', 'File', 'Content', 'Ġ=', 'Ġprops', '.', 'get', 'Property', '(', 'Ġkey', 'Ġ);', 'ĠString', 'Ġreal', 'Key', 'Ġ=', 'Ġkey', '.', 'sub', 'string', '(', 'ĠEN', 'CODE', '_', 'FILE', '_', 'CONT', 'ENT', '_', 'PRE', 'FIX', '.', 'length', '());', 'Ġif', '(', 'Ġencoded', 'File', 'Content', 'Ġ==', 'Ġnull', 'Ġ)', 'Ġ{', 'Ġlogger', '.', 'f', 'ine', '(', 'Ġ\"', 'No', 'Ġfile', 'Ġcontent', 'Ġwas', 'Ġprovided', 'Ġfor', 'Ġ\"', 'Ġ+', 'Ġreal', 'Key', 'Ġ+', 'Ġ\".', 'ĠSk', 'ipping', 'Ġit', '...\"', 'Ġ);', 'Ġcontinue', ';', 'Ġ}', 'Ġbyte', '[]', 'Ġfile', 'Content', 'Ġ=', 'Ġdec', 'ode', 'From', 'Base', '6', '4', '(', 'Ġencoded', 'File', 'Content', 'Ġ);', 'ĠString', 'Ġtarget', 'File', 'Ġ=', 'Ġprops', '.', 'get', 'Property', '(', 'Ġreal', 'Key', 'Ġ);', 'Ġif', '(', 'Ġtarget', 'File', 'Ġ==', 'Ġnull', 'Ġ)', 'Ġ{', 'Ġlogger', '.', 'f', 'ine', '(', 'Ġ\"', 'No', 'Ġproperty', 'Ġnamed', 'Ġ\"', 'Ġ+', 'Ġreal', 'Key', 'Ġ+', 'Ġ\"', 'Ġwas', 'Ġfound', '.', 'ĠSk', 'ipping', 'Ġit', '...\"', 'Ġ);', 'Ġcontinue', ';', 'Ġ}', 'ĠUtil', 's', '.', 'create', 'Directory', '(', 'Ġoutput', 'Directory', 'Ġ);', 'ĠFile', 'Ġoutput', 'Ġ=', 'Ġnew', 'ĠFile', '(', 'Ġoutput', 'Directory', ',', 'Ġnew', 'ĠFile', '(', 'Ġtarget', 'File', 'Ġ).', 'getName', '());', 'ĠUtil', 's', '.', 'copy', 'Stream', '(', 'Ġnew', 'ĠByte', 'Array', 'InputStream', '(', 'Ġfile', 'Content', 'Ġ),', 'Ġoutput', 'Ġ);', 'Ġlogger', '.', 'fin', 'er', '(', 'Ġ\"', 'W', 'riting', 'Ġ\"', 'Ġ+', 'Ġkey', 'Ġ+', 'Ġ\"', 'Ġfrom', 'Ġuser', 'Ġdata', 'Ġin', 'Ġ\"', 'Ġ+', 'Ġoutput', '.', 'get', 'Abs', 'olute', 'Path', '());', 'Ġprops', '.', 'remove', '(', 'Ġkey', 'Ġ);', 'Ġprops', '.', 'set', 'Property', '(', 'Ġreal', 'Key', ',', 'Ġoutput', '.', 'get', 'Abs', 'olute', 'Path', '());', 'Ġ}', 'Ġ}', 'Ġprivate', 'Ġ', 'ĠUser', 'Data', 'Hel', 'pers', '();', 'Ġstatic', 'ĠString', 'Ġwrite', 'User', 'Data', 'As', 'String', '(', 'Ċ', 'ĉĉ', 'ĉ', 'Map', '<', 'String', ',', 'String', '>', 'Ġmess', 'aging', 'Configuration', ',', 'Ċ', 'ĉĉ', 'ĉString', 'Ġdomain', ',', 'Ċ', 'ĉĉ', 'ĉString', 'Ġapplication', 'Name', ',', 'Ċ', 'ĉĉ', 'ĉString', 'Ġsc', 'oped', 'Instance', 'Path', 'Ġ);', 'Ġstatic', 'ĠProperties', 'Ġwrite', 'User', 'Data', 'As', 'Properties', '(', 'Ċ', 'ĉĉ', 'ĉ', 'Map', '<', 'String', ',', 'String', '>', 'Ġmess', 'aging', 'Configuration', ',', 'Ċ', 'ĉĉ', 'ĉString', 'Ġdomain', ',', 'Ċ', 'ĉĉ', 'ĉString', 'Ġapplication', 'Name', ',', 'Ċ', 'ĉĉ', 'ĉString', 'Ġsc', 'oped', 'Instance', 'Path', 'Ġ);', 'Ġstatic', 'ĠProperties', 'Ġread', 'User', 'Data', '(', 'ĠString', 'Ġraw', 'Properties', ',', 'ĠFile', 'Ġoutput', 'Directory', 'Ġ);', 'Ġstatic', 'ĠProperties', 'Ġprocess', 'User', 'Data', '(', 'ĠProperties', 'Ġproperties', ',', 'ĠFile', 'Ġoutput', 'Directory', 'Ġ);', 'Ġstatic', 'Ġfinal', 'ĠString', 'ĠS', 'CO', 'P', 'ED', '_', 'INST', 'ANCE', '_', 'PATH', ';', 'Ġstatic', 'Ġfinal', 'ĠString', 'ĠAP', 'PL', 'ICATION', '_', 'NAME', ';', 'Ġstatic', 'Ġfinal', 'ĠString', 'ĠDOM', 'AIN', ';', 'Ġstatic', 'Ġfinal', 'ĠString', 'ĠEN', 'CODE', '_', 'FILE', '_', 'CONT', 'ENT', '_', 'PRE', 'FIX', ';', 'Ġ}']\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.convert_tokens_to_string(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:48.414031Z","iopub.execute_input":"2024-09-05T13:13:48.414409Z","iopub.status.idle":"2024-09-05T13:13:48.422464Z","shell.execute_reply.started":"2024-09-05T13:13:48.414317Z","shell.execute_reply":"2024-09-05T13:13:48.421631Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'<｜begin▁of▁sentence｜>Generate a unit test case for the following Java method: UserDataHelpers { static void interceptWritingFiles( Properties props, File outputDirectory ) throws IOException { if( outputDirectory == null ) return; Logger logger = Logger.getLogger( UserDataHelpers.class.getName()); Set<String> keys = props.stringPropertyNames(); for( final String key : keys ) { if( ! key.startsWith( ENCODE_FILE_CONTENT_PREFIX )) continue; String encodedFileContent = props.getProperty( key ); String realKey = key.substring( ENCODE_FILE_CONTENT_PREFIX.length()); if( encodedFileContent == null ) { logger.fine( \"No file content was provided for \" + realKey + \". Skipping it...\" ); continue; } byte[] fileContent = decodeFromBase64( encodedFileContent ); String targetFile = props.getProperty( realKey ); if( targetFile == null ) { logger.fine( \"No property named \" + realKey + \" was found. Skipping it...\" ); continue; } Utils.createDirectory( outputDirectory ); File output = new File( outputDirectory, new File( targetFile ).getName()); Utils.copyStream( new ByteArrayInputStream( fileContent ), output ); logger.finer( \"Writing \" + key + \" from user data in \" + output.getAbsolutePath()); props.remove( key ); props.setProperty( realKey, output.getAbsolutePath()); } } private  UserDataHelpers(); static String writeUserDataAsString(\\n\\t\\t\\tMap<String,String> messagingConfiguration,\\n\\t\\t\\tString domain,\\n\\t\\t\\tString applicationName,\\n\\t\\t\\tString scopedInstancePath ); static Properties writeUserDataAsProperties(\\n\\t\\t\\tMap<String,String> messagingConfiguration,\\n\\t\\t\\tString domain,\\n\\t\\t\\tString applicationName,\\n\\t\\t\\tString scopedInstancePath ); static Properties readUserData( String rawProperties, File outputDirectory ); static Properties processUserData( Properties properties, File outputDirectory ); static final String SCOPED_INSTANCE_PATH; static final String APPLICATION_NAME; static final String DOMAIN; static final String ENCODE_FILE_CONTENT_PREFIX; }'"},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Vocab size : {tokenizer.vocab_size}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:48.423622Z","iopub.execute_input":"2024-09-05T13:13:48.424280Z","iopub.status.idle":"2024-09-05T13:13:48.432530Z","shell.execute_reply.started":"2024-09-05T13:13:48.424245Z","shell.execute_reply":"2024-09-05T13:13:48.431630Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Vocab size : 32000\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"max length : {tokenizer.model_max_length}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:48.433635Z","iopub.execute_input":"2024-09-05T13:13:48.433950Z","iopub.status.idle":"2024-09-05T13:13:48.443122Z","shell.execute_reply.started":"2024-09-05T13:13:48.433919Z","shell.execute_reply":"2024-09-05T13:13:48.442236Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"max length : 16384\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"model input : {tokenizer.model_input_names}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:48.444070Z","iopub.execute_input":"2024-09-05T13:13:48.444342Z","iopub.status.idle":"2024-09-05T13:13:48.454554Z","shell.execute_reply.started":"2024-09-05T13:13:48.444298Z","shell.execute_reply":"2024-09-05T13:13:48.453820Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"model input : ['input_ids', 'attention_mask']\n","output_type":"stream"}]},{"cell_type":"code","source":"batch = tokenizer(train['instruction'][0],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\nprint(batch)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:48.456375Z","iopub.execute_input":"2024-09-05T13:13:48.456803Z","iopub.status.idle":"2024-09-05T13:13:48.503242Z","shell.execute_reply.started":"2024-09-05T13:13:48.456762Z","shell.execute_reply":"2024-09-05T13:13:48.502456Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[32014, 32014, 32014, 32014, 32014, 32014, 32014, 32014, 32014, 32014,\n         32014, 32014, 32014, 32014, 32014, 32014, 32014, 32014, 32014, 32014,\n         32014, 32014, 32014, 32014, 32014, 32013,  7605,   387,   245,  5621,\n          1719,  1452,   327,   254,  1884,  9840,  2040,    25, 10481,  2714,\n          7746,  6474,   507,  3314,  2494,  1193,  1597,    54, 11943, 14667,\n             7, 25924, 22116,    11,  7050,  2816, 16262,  2189,  8474, 20685,\n           507,   562,     7,  2816, 16262,  2312,  2352,  2189,   967,    26,\n          6977,  1964, 22301,   405,  6977,  1964,    13,   703, 18451,     7,\n         10481,  2714,  7746,  6474,    13,  2176,    13, 19796,  3705,  4450,\n            27,  2005,    29,  8729,   405, 22116,    13,  2600,  6353, 10269,\n          1293,   327,     7,  2319,  3270,  2119,  1191,  8729,  2189,   507,\n           562,     7,  2069,  2119,    13,  4779,    82,  3209,     7, 16170,\n         11087,    62, 12929,    62, 25563,  4208,    62, 11787, 30383,   207,\n          1435,  4873,    26,  3270, 27492,  3882,  7261,   405, 22116,    13,\n           703,  6353,     7,  2119,  4363,  3270,  1582,  3790,   405,  2119,\n            13,  1580,  2600,     7, 16170, 11087,    62, 12929,    62, 25563,\n          4208,    62, 11787, 30383,    13,  4082,  3705,   562,     7, 27492,\n          3882,  7261,  2312,  2352,  2189,   507, 22301,    13,    69,   480,\n             7,   440,  3221,  1753,  3082,   438,  4274,   327,   440,   945,\n          1582,  3790,   945, 19736,  7030, 12510,   359, 12058,  4363,  4873,\n            26,   611, 12477,  4807,  1753,  7261,   405,  1450,   734,  4034,\n          7190,    21,    19,     7, 27492,  3882,  7261,  4363,  3270,  3393,\n          3882,   405, 22116,    13,   703,  6353,     7,  1582,  3790,  4363,\n           562,     7,  3393,  3882,  2312,  2352,  2189,   507, 22301,    13,\n            69,   480,     7,   440,  3221,  3574,  7046,   440,   945,  1582,\n          3790,   945,   440,   438,  1496,    13,  7030, 12510,   359, 12058,\n          4363,  4873,    26,   611, 22856,    82,    13,  4981, 16262,     7,\n          2816, 16262,  4363,  7050,  2816,   405,   756,  7050,     7,  2816,\n         16262,    11,   756,  7050,     7,  3393,  3882, 16851, 19796,  3705,\n         22856,    82,    13, 11792,  6620,     7,   756, 31178,  5055, 24734,\n             7,  1753,  7261, 12651,  2816,  4363, 22301,    13,  4647,   250,\n             7,   440,    54, 11943,   440,   945,  2119,   945,   440,   473,\n          2664,  1189,   279,   440,   945,  2816,    13,   703, 22169, 20748,\n          4693,  3705, 22116,    13,  8680,     7,  2119,  4363, 22116,    13,\n          1113,  6353,     7,  1582,  3790,    11,  2816,    13,   703, 22169,\n         20748,  4693,  3705,   611,   611,  2740,   207, 10481,  2714,  7746,\n          6474,  1293,  3314,  3270,  3697,  5719,  2714,  2111,  2005,     7,\n           185,   459,   184,  4581,    27,  2005,    11,  2005,    29,  5659,\n          4243, 11312,    11,   185,   459, 28637,  6980,    11,   185,   459,\n         28637,  3708,  1737,    11,   185,   459, 28637,   752, 13683,  7552,\n          4693,  4363,  3314, 25924,  3697,  5719,  2714,  2111, 12461,     7,\n           185,   459,   184,  4581,    27,  2005,    11,  2005,    29,  5659,\n          4243, 11312,    11,   185,   459, 28637,  6980,    11,   185,   459,\n         28637,  3708,  1737,    11,   185,   459, 28637,   752, 13683,  7552,\n          4693,  4363,  3314, 25924,  1272,  5719,  2714,     7,  3270, 11681,\n         12461,    11,  7050,  2816, 16262,  4363,  3314, 25924,  1694,  5719,\n          2714,     7, 25924,  5289,    11,  7050,  2816, 16262,  4363,  3314,\n          2319,  3270,   324,  3008,    47,  2289,    62, 24607, 18711,    62,\n         14348,    26,  3314,  2319,  3270, 10538,  8124, 25709,    62,  8648,\n            26,  3314,  2319,  3270, 23152, 28500,    26,  3314,  2319,  3270,\n         16170, 11087,    62, 12929,    62, 25563,  4208,    62, 11787, 30383,\n            26,   611]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1]])}\n","output_type":"stream"}]},{"cell_type":"code","source":"# tmp=Dataset.from_list(tmp)\n# tmp","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:48.504187Z","iopub.execute_input":"2024-09-05T13:13:48.504464Z","iopub.status.idle":"2024-09-05T13:13:48.508094Z","shell.execute_reply.started":"2024-09-05T13:13:48.504434Z","shell.execute_reply":"2024-09-05T13:13:48.507172Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def build_instruction_prompt(instruction: str):\n    return '''\nYou are an AI programming assistant, utilizing the DeepSeek Coder model, developed by DeepSeek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n### Instruction:\n{}\n### Response:\n'''.format(instruction.strip()).lstrip()\n\n# Define the EOT_TOKEN\nEOT_TOKEN = \"<|EOT|>\"","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:48.509215Z","iopub.execute_input":"2024-09-05T13:13:48.509570Z","iopub.status.idle":"2024-09-05T13:13:48.520053Z","shell.execute_reply.started":"2024-09-05T13:13:48.509528Z","shell.execute_reply":"2024-09-05T13:13:48.519276Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def tokenize_data(data):\n  input_col=tokenizer(data['instruction'],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n  target_col=tokenizer(data['output'],max_length=512,truncation=True,padding=\"max_length\",return_tensors=\"pt\")\n\n  return {\n      \"input_ids\":input_col[\"input_ids\"],\n      \"attention_mask\":input_col[\"attention_mask\"],\n      \"labels\":target_col[\"input_ids\"]\n  }","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:48.520992Z","iopub.execute_input":"2024-09-05T13:13:48.521270Z","iopub.status.idle":"2024-09-05T13:13:48.531640Z","shell.execute_reply.started":"2024-09-05T13:13:48.521240Z","shell.execute_reply":"2024-09-05T13:13:48.530833Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"tokenizer.padding_side = \"right\"\nprint(\"Tokenizing dataset...\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:50.164988Z","iopub.execute_input":"2024-09-05T13:13:50.165801Z","iopub.status.idle":"2024-09-05T13:13:50.170065Z","shell.execute_reply.started":"2024-09-05T13:13:50.165763Z","shell.execute_reply":"2024-09-05T13:13:50.169160Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Tokenizing dataset...\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Mapping train data...\")\ntrain=train.map(tokenize_data,batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:51.087735Z","iopub.execute_input":"2024-09-05T13:13:51.088148Z","iopub.status.idle":"2024-09-05T13:13:52.647975Z","shell.execute_reply.started":"2024-09-05T13:13:51.088108Z","shell.execute_reply":"2024-09-05T13:13:52.647123Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Mapping train data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a0093ffb02947168d9ac1b428493ba0"}},"metadata":{}}]},{"cell_type":"code","source":"print(train)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:52.649433Z","iopub.execute_input":"2024-09-05T13:13:52.649723Z","iopub.status.idle":"2024-09-05T13:13:52.654547Z","shell.execute_reply.started":"2024-09-05T13:13:52.649678Z","shell.execute_reply":"2024-09-05T13:13:52.653666Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['instruction', 'output', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 800\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Mappig test data...\")\ntest=test.map(tokenize_data,batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:52.655638Z","iopub.execute_input":"2024-09-05T13:13:52.655955Z","iopub.status.idle":"2024-09-05T13:13:53.085579Z","shell.execute_reply.started":"2024-09-05T13:13:52.655923Z","shell.execute_reply":"2024-09-05T13:13:53.084728Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Mappig test data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d5f1ccac6944808ad84ddbea485e160"}},"metadata":{}}]},{"cell_type":"code","source":"print(test)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:53.087670Z","iopub.execute_input":"2024-09-05T13:13:53.088018Z","iopub.status.idle":"2024-09-05T13:13:53.092890Z","shell.execute_reply.started":"2024-09-05T13:13:53.087967Z","shell.execute_reply":"2024-09-05T13:13:53.091878Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['instruction', 'output', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 200\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"train=train.remove_columns([\"instruction\",\"output\"])\ntest=test.remove_columns([\"instruction\",\"output\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:53.094001Z","iopub.execute_input":"2024-09-05T13:13:53.094301Z","iopub.status.idle":"2024-09-05T13:13:53.106260Z","shell.execute_reply.started":"2024-09-05T13:13:53.094267Z","shell.execute_reply":"2024-09-05T13:13:53.105358Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(train)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:53.107234Z","iopub.execute_input":"2024-09-05T13:13:53.107487Z","iopub.status.idle":"2024-09-05T13:13:53.120797Z","shell.execute_reply.started":"2024-09-05T13:13:53.107458Z","shell.execute_reply":"2024-09-05T13:13:53.119664Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 800\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n    device={\"\":0}\n    torch_type=torch.bfloat16\nelse:\n    device=\"cpu\"\n    torch_type=torch.bfloat16\n    print(\"I am begging for mercy already!\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:53.122012Z","iopub.execute_input":"2024-09-05T13:13:53.123357Z","iopub.status.idle":"2024-09-05T13:13:53.185224Z","shell.execute_reply.started":"2024-09-05T13:13:53.123323Z","shell.execute_reply":"2024-09-05T13:13:53.184304Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"CUDA device: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return f'trainable model parameters: {trainable_model_params}\\n \\\n            all model parameters: {all_model_params} \\n \\\n            percentage of trainable model parameters: {(trainable_model_params / all_model_params) * 100} %'","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:53.186231Z","iopub.execute_input":"2024-09-05T13:13:53.186501Z","iopub.status.idle":"2024-09-05T13:13:53.191607Z","shell.execute_reply.started":"2024-09-05T13:13:53.186472Z","shell.execute_reply":"2024-09-05T13:13:53.190754Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()  # release CUDA memory","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:53.192922Z","iopub.execute_input":"2024-09-05T13:13:53.193460Z","iopub.status.idle":"2024-09-05T13:13:53.201957Z","shell.execute_reply.started":"2024-09-05T13:13:53.193416Z","shell.execute_reply":"2024-09-05T13:13:53.200997Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"**Nested quantization**\nFor enabling nested quantization, use the bnb_4bit_use_double_quant argument in BitsAndBytesConfig. This will enable a second quantization after the first one to save an additional 0.4 bits per parameter.","metadata":{}},{"cell_type":"code","source":"nf4_config = BitsAndBytesConfig(\n   load_in_4bit=True,\n   bnb_4bit_quant_type=\"nf4\",\n   bnb_4bit_use_double_quant=True,\n   bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel_nf4 = AutoModelForCausalLM.from_pretrained(base_model, quantization_config=nf4_config)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:13:58.975354Z","iopub.execute_input":"2024-09-05T13:13:58.975751Z","iopub.status.idle":"2024-09-05T13:18:05.147677Z","shell.execute_reply.started":"2024-09-05T13:13:58.975715Z","shell.execute_reply":"2024-09-05T13:18:05.146667Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b531f9a0b12a44e2ade9cde6a6fec965"}},"metadata":{}},{"name":"stderr","text":"Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b1f3fab35e74c0b90e340456eb82ae0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98639933ef7249b3b950515a2248eedd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa587de3ddae4c7d8334355e3b2607a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b70cf9daabe44241b18db99fa47d4fc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5422e55d1c0c470aab857341c6b2d02b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"340f7f7958d04f0ab46aac986ecc5a9f"}},"metadata":{}}]},{"cell_type":"code","source":"print(model_nf4)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:18:19.580399Z","iopub.execute_input":"2024-09-05T13:18:19.581169Z","iopub.status.idle":"2024-09-05T13:18:19.588768Z","shell.execute_reply.started":"2024-09-05T13:18:19.581129Z","shell.execute_reply":"2024-09-05T13:18:19.587817Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(32256, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n      )\n    )\n    (norm): LlamaRMSNorm((4096,), eps=1e-06)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32256, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(print_number_of_trainable_model_parameters(model_nf4))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:18:36.411463Z","iopub.execute_input":"2024-09-05T13:18:36.412168Z","iopub.status.idle":"2024-09-05T13:18:36.419406Z","shell.execute_reply.started":"2024-09-05T13:18:36.412126Z","shell.execute_reply":"2024-09-05T13:18:36.418462Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"trainable model parameters: 264507392\n             all model parameters: 3502510080 \n             percentage of trainable model parameters: 7.5519380660854525 %\n","output_type":"stream"}]},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=64,\n    lora_alpha=16,\n    lora_dropout = 0.1,\n    bias='none',\n    task_type=\"CAUSAL_LM\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:18:37.675188Z","iopub.execute_input":"2024-09-05T13:18:37.675849Z","iopub.status.idle":"2024-09-05T13:18:37.680308Z","shell.execute_reply.started":"2024-09-05T13:18:37.675808Z","shell.execute_reply":"2024-09-05T13:18:37.679329Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# peft_model = get_peft_model(model, lora_config)\npeft_model = get_peft_model(model_nf4, lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:18:39.065098Z","iopub.execute_input":"2024-09-05T13:18:39.065997Z","iopub.status.idle":"2024-09-05T13:18:39.606360Z","shell.execute_reply.started":"2024-09-05T13:18:39.065958Z","shell.execute_reply":"2024-09-05T13:18:39.605351Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"print(peft_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:18:40.917236Z","iopub.execute_input":"2024-09-05T13:18:40.917624Z","iopub.status.idle":"2024-09-05T13:18:40.929595Z","shell.execute_reply.started":"2024-09-05T13:18:40.917586Z","shell.execute_reply":"2024-09-05T13:18:40.928712Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(32256, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=64, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-06)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=32256, bias=False)\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(print_number_of_trainable_model_parameters(peft_model))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:18:51.206830Z","iopub.execute_input":"2024-09-05T13:18:51.207217Z","iopub.status.idle":"2024-09-05T13:18:51.217957Z","shell.execute_reply.started":"2024-09-05T13:18:51.207181Z","shell.execute_reply":"2024-09-05T13:18:51.216953Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"trainable model parameters: 33554432\n             all model parameters: 3536064512 \n             percentage of trainable model parameters: 0.9489202441338265 %\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"BF16 support is {transformers.file_utils.is_torch_bf16_available()}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:18:52.301006Z","iopub.execute_input":"2024-09-05T13:18:52.301671Z","iopub.status.idle":"2024-09-05T13:18:52.308583Z","shell.execute_reply.started":"2024-09-05T13:18:52.301622Z","shell.execute_reply":"2024-09-05T13:18:52.307743Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"BF16 support is True\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:455: FutureWarning: The util is_torch_bf16_available is deprecated, please use is_torch_bf16_gpu_available or is_torch_bf16_cpu_available instead according to whether it's used with cpu or gpu\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    run_name =\"./loggings\",\n    overwrite_output_dir=True,\n    eval_strategy=\"steps\",\n    learning_rate=5e-5, # default, change to 1e-3 later\n    gradient_accumulation_steps=1, # if CUDA out of memory = 3,4\n#     per_device_train_batch_size=8,\n#     per_device_eval_batch_size=8,\n    auto_find_batch_size = True, # for CUDA out of memory \n    weight_decay=0.01,\n    num_train_epochs=1, # test=1, min=4, max=10\n    bf16=True,\n    optim=\"adamw_torch\", \n    save_strategy=\"no\",\n    log_level=\"info\",\n    logging_first_step=True,\n    report_to='none' ## can be wandb, but we dont need right now!\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:20:28.488668Z","iopub.execute_input":"2024-09-05T13:20:28.489533Z","iopub.status.idle":"2024-09-05T13:20:28.518532Z","shell.execute_reply.started":"2024-09-05T13:20:28.489491Z","shell.execute_reply":"2024-09-05T13:20:28.517603Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=peft_model,\n    train_dataset=train,\n    eval_dataset=test,\n    peft_config=lora_config,\n    dataset_text_field=\"text\",\n    max_seq_length=None,\n    tokenizer=tokenizer,\n    args=training_args,\n    packing=False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:22:27.626732Z","iopub.execute_input":"2024-09-05T13:22:27.627675Z","iopub.status.idle":"2024-09-05T13:22:27.679825Z","shell.execute_reply.started":"2024-09-05T13:22:27.627630Z","shell.execute_reply":"2024-09-05T13:22:27.678896Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:292: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\nUsing auto half precision backend\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:21:42.505071Z","iopub.execute_input":"2024-09-05T13:21:42.505817Z","iopub.status.idle":"2024-09-05T13:21:43.573363Z","shell.execute_reply.started":"2024-09-05T13:21:42.505775Z","shell.execute_reply":"2024-09-05T13:21:43.572400Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Thu Sep  5 13:21:43 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P0             32W /  250W |    4415MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T13:22:34.026020Z","iopub.execute_input":"2024-09-05T13:22:34.026493Z","iopub.status.idle":"2024-09-05T14:02:03.578883Z","shell.execute_reply.started":"2024-09-05T13:22:34.026455Z","shell.execute_reply":"2024-09-05T14:02:03.577992Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stderr","text":"***** Running training *****\n  Num examples = 800\n  Num Epochs = 1\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 100\n  Number of trainable parameters = 33,554,432\n***** Running training *****\n  Num examples = 800\n  Num Epochs = 1\n  Instantaneous batch size per device = 8\n  Training with DataParallel so batch size has been adjusted to: 4\n  Total train batch size (w. parallel, distributed & accumulation) = 4\n  Gradient Accumulation steps = 1\n  Total optimization steps = 200\n  Number of trainable parameters = 33,554,432\n***** Running training *****\n  Num examples = 800\n  Num Epochs = 1\n  Instantaneous batch size per device = 8\n  Training with DataParallel so batch size has been adjusted to: 2\n  Total train batch size (w. parallel, distributed & accumulation) = 2\n  Gradient Accumulation steps = 1\n  Total optimization steps = 400\n  Number of trainable parameters = 33,554,432\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [400/400 39:11, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=400, training_loss=1.0186097171902657, metrics={'train_runtime': 2357.4812, 'train_samples_per_second': 0.339, 'train_steps_per_second': 0.17, 'total_flos': 1.63232480231424e+16, 'train_loss': 1.0186097171902657, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:08:27.225859Z","iopub.execute_input":"2024-09-05T14:08:27.226806Z","iopub.status.idle":"2024-09-05T14:08:28.293805Z","shell.execute_reply.started":"2024-09-05T14:08:27.226762Z","shell.execute_reply":"2024-09-05T14:08:28.292751Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Thu Sep  5 14:08:28 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   43C    P0             33W /  250W |   13561MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.model.save_pretrained(new_model)\ntrainer.tokenizer.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:08:31.670295Z","iopub.execute_input":"2024-09-05T14:08:31.671272Z","iopub.status.idle":"2024-09-05T14:08:32.423231Z","shell.execute_reply.started":"2024-09-05T14:08:31.671224Z","shell.execute_reply":"2024-09-05T14:08:32.422277Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--deepseek-ai--deepseek-coder-6.7b-instruct/snapshots/e5d64addd26a6a1db0f9b863abf6ee3141936807/config.json\nUnrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\nModel config LlamaConfig {\n  \"_name_or_path\": \"/3fs-jd/prod/deepseek/shared/zhuqihao/public_model/deepseek-coder-7b-instruct2\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 32013,\n  \"eos_token_id\": 32021,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 16384,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 32,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": {\n    \"factor\": 4.0,\n    \"rope_type\": \"linear\",\n    \"type\": \"linear\"\n  },\n  \"rope_theta\": 100000,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.44.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 32256\n}\n\ntokenizer config file saved in CODEX-deepseek-coder-6.7b-instruct/tokenizer_config.json\nSpecial tokens file saved in CODEX-deepseek-coder-6.7b-instruct/special_tokens_map.json\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"('CODEX-deepseek-coder-6.7b-instruct/tokenizer_config.json',\n 'CODEX-deepseek-coder-6.7b-instruct/special_tokens_map.json',\n 'CODEX-deepseek-coder-6.7b-instruct/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"torch.cuda.empty_cache()  # release CUDA memory","metadata":{"execution":{"iopub.status.busy":"2024-09-05T14:08:35.969782Z","iopub.execute_input":"2024-09-05T14:08:35.970663Z","iopub.status.idle":"2024-09-05T14:08:36.304964Z","shell.execute_reply.started":"2024-09-05T14:08:35.970611Z","shell.execute_reply":"2024-09-05T14:08:36.303776Z"},"trusted":true},"execution_count":60,"outputs":[]}]}